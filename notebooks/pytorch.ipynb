{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add parent folder to the path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader # load batches to the network\n",
    "\n",
    "# architectures\n",
    "from src.models import (\n",
    "    SimpleNet,\n",
    "    Rodan\n",
    ")\n",
    "\n",
    "# loss function and dataset loader\n",
    "from src.dataloader import DatasetONT # custom loader (used with DataLoader)\n",
    "from src.loss_functions import ctc_label_smoothing # custom CTC loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input [batch size, channels, length]: torch.Size([2, 1, 4096])\n",
      "Output [batch size, length]: torch.Size([2, 271])\n",
      "CTC Loss\n",
      "Input CTC Loss [batch size] torch.Size([2])\n",
      "Target CTC Loss [batch size] torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "output_simplenet = 501\n",
    "dataset_example = DatasetONT(recfile=\"../data/subsample_val.hdf5\", output_network_len=output_simplenet)\n",
    "loader = iter(DataLoader(dataset_example, batch_size=2, shuffle=True))\n",
    "x,y, input_len, target_len = next(loader)\n",
    "print(\"Input [batch size, channels, length]:\" , x.shape)\n",
    "print(\"Output [batch size, length]:\" , y.shape)\n",
    "print(\"CTC Loss\")\n",
    "print(\"Input CTC Loss [batch size]\", input_len.shape)\n",
    "print(\"Target CTC Loss [batch size]\", target_len.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([501, 501]), tensor([271, 271]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_len, target_len"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "SimpleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (conv1): Conv1d(1, 20, kernel_size=(20,), stride=(2,))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool1d(kernel_size=10, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(20, 50, kernel_size=(5,), stride=(1,))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool1d(kernel_size=10, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=50, out_features=5, bias=True)\n",
       "  (relu3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplenet = SimpleNet(n_channels = 1, n_classes = 271)\n",
    "simplenet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 2, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = simplenet(x)\n",
    "output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "RODAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import namedtuple\n",
    "# DEFAULTCONFIG = dict(\n",
    "#     vocab=[\"<PAD>\", \"A\", \"C\", \"G\", \"T\"],\n",
    "#     activation_layer=\"mish\", # options: mish, swish, relu, gelu\n",
    "#     sqex_activation=\"mish\", # options: mish, swish, relu, gelu\n",
    "#     dropout=0.1,\n",
    "#     sqex_reduction=32\n",
    "# )\n",
    "\n",
    "# Config=namedtuple(\"CONFIG\",[\"vocab\", \"activation\", \"sqex_activation\", \"dropout\", \"sqex_reduction\"])\n",
    "\n",
    "# rodan = Rodan(config=Config(*DEFAULTCONFIG.values()))\n",
    "# rodan.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y, input_len, target_len = next(loader)\n",
    "# print(\"Input [batch size, channels, length]:\" , x.shape)\n",
    "# print(\"Input [batch size, length]:\" , y.shape)\n",
    "\n",
    "# output_rodan = rodan(x)\n",
    "# print(\"output rodan:\", output_rodan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 200)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader_train), len(dataloader_train.dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, epoch: Optional[int]):\n",
    "    \"\"\"\n",
    "    training function\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset) # number of datapoints in the dataset\n",
    "    n_batches = len(dataloader)    # number of batches\n",
    "    model.train() # set model in training mode\n",
    "\n",
    "    with tqdm(total=n_batches) as pbar:\n",
    "        \n",
    "        for batch, (X,y, input_len, target_len) in enumerate(dataloader):\n",
    "            \n",
    "            # Description for progress bar\n",
    "            if epoch:\n",
    "                pbar.set_description(f\"Epoch: {epoch} | batch: {batch}/{n_batches}\")\n",
    "            else:\n",
    "                pbar.set_description(f\"batch {batch}/{n_batches}\")\n",
    "            \n",
    "                \n",
    "            X, y, input_len, target_len = X.to(device), y.to(device), input_len.to(device), target_len.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y, input_lengths=input_len, target_lengths=target_len)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 100 == 0: \n",
    "                loss, current = loss.item(), (batch + 1) * len(X)\n",
    "                # print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "            # update progress bar\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, model_metadata=None):\n",
    "    \"\"\"\n",
    "    test function\n",
    "\n",
    "    Accuracy is measured here\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() # let the model know that is in evaluation model\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X,y, input_len, target_len) in enumerate(dataloader):\n",
    "            X, y, input_len, target_len = X.to(device), y.to(device), input_len.to(device), target_len.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y, input_lengths=input_len, target_lengths=target_len).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture\n",
    "model = simplenet\n",
    "# simplenet params\n",
    "simplenet_output_len = 501\n",
    "rodan_output_len = 420 \n",
    "\n",
    "# params\n",
    "epochs = 5\n",
    "\n",
    "# dataset\n",
    "dataset_train = DatasetONT(recfile=\"../data/subsample_train.hdf5\", output_network_len=simplenet_output_len)\n",
    "dataset_val   = DatasetONT(recfile=\"../data/subsample_val.hdf5\", output_network_len=simplenet_output_len)\n",
    "\n",
    "dataloader_train = DataLoader(dataset_val, batch_size=16, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=16, shuffle=False)\n",
    "\n",
    "# loss function and optimizer\n",
    "loss_fn = nn.CTCLoss() #ctc_label_smoothing # \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CTCLoss() #ctc_label_smoothing # \n",
    "\n",
    "for batch, (X,y, input_len, target_len) in enumerate(dataloader_train):\n",
    "    X, y, input_len, target_len = X.to(device), y.to(device), input_len.to(device), target_len.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y, input_lengths=input_len, target_lengths=target_len)\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([501, 8, 5]),\n",
       " torch.Size([8, 271]),\n",
       " tensor([501, 501, 501, 501, 501, 501, 501, 501]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, y.shape, input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(561)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array(561))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1| batch: 12/13: 100%|██████████| 13/13 [00:08<00:00,  1.54it/s]\n",
      "Epoch: 2| batch: 12/13: 100%|██████████| 13/13 [00:08<00:00,  1.45it/s]\n",
      "Epoch: 3| batch: 12/13: 100%|██████████| 13/13 [00:09<00:00,  1.32it/s]\n",
      "Epoch: 4| batch: 12/13: 100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n",
      "Epoch: 5| batch: 12/13: 100%|██████████| 13/13 [00:08<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run training \n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch = t+1\n",
    "    train(dataloader_train, model=model, loss_fn=loss_fn, optimizer=optimizer, epoch=epoch)\n",
    "    # test(dataloader_val, model=model, loss_fn=loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4096])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rodan(x)\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## basecalling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "alphabet = \"NACGT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posteriors = output_rodan[:,1,:].detach().numpy()\n",
    "seq, path = viterbi_search(posteriors, alphabet)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "posteriors = np.random.rand(100, len(alphabet)).astype(np.float32)\n",
    "posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, path = viterbi_search(posteriors, alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GATCTCTATATGTGTATCACAGCAGTCATCTCATCGACGCACTCACT', 47)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, len(seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 14,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 28,\n",
       " 29,\n",
       " 32,\n",
       " 35,\n",
       " 37,\n",
       " 40,\n",
       " 41,\n",
       " 43,\n",
       " 46,\n",
       " 48,\n",
       " 50,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 56,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 68,\n",
       " 70,\n",
       " 72,\n",
       " 75,\n",
       " 78,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GATCTCTATATGTGTATCACAGCAGTCATCTCATCGACGCACTCACT', 47)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq, path = beam_search(posteriors, alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "seq, len(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
