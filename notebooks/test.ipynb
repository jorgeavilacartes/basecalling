{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add parent folder to the path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import parasail\n",
    "# result = parasail.sw_scan_16(\"asdf\", \"asdf\", 11, 1, parasail.blosum62)\n",
    "# result = parasail.sw_stats_striped_8(\"asdf\", \"asdf\", 11, 1, parasail.pam100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin libraries\n",
    "import re\n",
    "import logging\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "\n",
    "# secondary libraries\n",
    "import numpy as np\n",
    "import parasail\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader # load batches to the network\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "from tqdm import tqdm\n",
    "\n",
    "# feito \n",
    "# from basecaller_tester import BasecallerTester as Tester\n",
    "from feito.models import SimpleNet, Rodan\n",
    "from feito.dataloaders.dataloader import DatasetONT\n",
    "# from feito.callbacks import CSVLogger, ModelCheckpoint\n",
    "# ---- \n",
    "\n",
    "# types\n",
    "_Path = Union[Path,str]\n",
    "\n",
    "class BasecallerTester:\n",
    "    \n",
    "    split_cigar = re.compile(r\"(?P<len>\\d+)(?P<op>\\D+)\")\n",
    "    \n",
    "    def __init__(self, model, device, test_loader, path_fasta: Optional[_Path] = None, rna: bool = True, use_viterbi = True):\n",
    "        self.model  = model.to(device) # model with pretrained weigths loaded\n",
    "        self.device = device\n",
    "        self.test_loader = test_loader # load signals\n",
    "        self.batch_size  = test_loader.batch_size\n",
    "        self.path_fasta  = path_fasta # to save basecalled raw-reads (if not None)\n",
    "        self.rna = rna \n",
    "        self.alphabet    = \"NACGU\" if rna else \"NACGT\"\n",
    "        self.use_viterbi = use_viterbi\n",
    "        self.search_algo = viterbi_search if use_viterbi  else beam_search\n",
    "\n",
    "        # set evaluation/inference mode\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self,):\n",
    "        print(\"Que me dice\")\n",
    "        # TODO: implement tester, considering accuracy\n",
    "\n",
    "        # 1. generate output of a signal\n",
    "\n",
    "        # 2. call viterbi or beam search to generate portion of a read\n",
    "        \n",
    "        # 3. send to a fasta file\n",
    "\n",
    "        return \"\"\n",
    "    \n",
    "    def basecall_one_batch(self, X):\n",
    "        \"Return basecalled signals in the chosen alphabet\"\n",
    "        preds  = self.model(X) # preds shape: (len-signal, item, size-alphabet)\n",
    "        basecalled_signals = (self.signal_to_read(signal=preds[:,item,:], use_viterbi=self.use_viterbi, rna=self.rna) for item in range(self.batch_size))\n",
    "\n",
    "        return basecalled_signals\n",
    "\n",
    "    def label_to_alphabet(self, label):\n",
    "        \"Map vector of integers to sequence\"\n",
    "        int2char = {i:c for i,c in zip([1,2,3,4], self.alphabet.replace(\"N\",\"\"))}\n",
    "        return \"\".join([int2char[i] for i in label if i > 0])\n",
    "    \n",
    "    def accuracy_one_batch(self, batch):\n",
    "        X, y, output_len, target_len = (x.to(self.device) for x in batch)\n",
    "\n",
    "        basecalled_signals = self.basecall_one_batch(X)\n",
    "        ground_truth = np.apply_along_axis(lambda l: self.label_to_alphabet(l), 1, y.detach().numpy()) \n",
    "        accuracy_batch = [self.accuracy(ref=gt, seq=bs) for gt,bs in zip(basecalled_signals, ground_truth)]\n",
    "        \n",
    "        return accuracy_batch, basecalled_signals\n",
    "    \n",
    "    def accuracy_all_dataset(self,):\n",
    "        basecalled_signals = []\n",
    "        accuracies = []\n",
    "        n_batches=len(self.test_loader)\n",
    "    \n",
    "        with tqdm(total=n_batches, leave=True, ncols=100, bar_format='{l_bar}{bar}| [{elapsed}{postfix}]') as progress_bar:\n",
    "\n",
    "            for n_batch, batch in enumerate(self.test_loader):\n",
    "                \n",
    "                # Description for progress bar\n",
    "                progress_bar.set_description(f\"Evaluating | Batch: {n_batch+1}/{n_batches}\")\n",
    "                \n",
    "                # Compute accuracy\n",
    "                accuracy_batch, basecalled_signals_batch = self.accuracy_one_batch(batch)\n",
    "                accuracies.extend(accuracy_batch)\n",
    "\n",
    "                basecalled_signals.extend(basecalled_signals_batch)\n",
    "                # progress_bar.set_postfix(train_loss='%.4f' % current_avg_loss)\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        return accuracies, basecalled_signals\n",
    "\n",
    "    def signal_to_read(signal, use_viterbi: bool = True, rna: bool = True):\n",
    "        \"Apply viterbi or beam search to a batch\"\n",
    "        alphabet = \"NACGU\" if rna else \"NACGT\"\n",
    "        \n",
    "        if use_viterbi is True:\n",
    "            seq, path = viterbi_search(signal, alphabet) \n",
    "        else:\n",
    "            seq, path = beam_search(signal, alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, ref, seq, balanced=False, min_coverage=0.0):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L354\n",
    "        \"\"\"\n",
    "        Calculate the accuracy between `ref` and `seq`\n",
    "        \"\"\"\n",
    "        # alignment = parasail.sw_trace_striped_32(seq, ref, 8, 4, parasail.dnafull)\n",
    "        alignment = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        q_coverage = len(alignment.traceback.query) / len(seq)\n",
    "        r_coverage = len(alignment.traceback.ref) / len(ref)\n",
    "\n",
    "        if r_coverage < min_coverage:\n",
    "            return 0.0\n",
    "\n",
    "        _, cigar = self.parasail_to_sam(alignment, seq)\n",
    "\n",
    "        for count, op  in re.findall(self.split_cigar, cigar):\n",
    "            counts[op] += int(count)\n",
    "\n",
    "        if balanced:\n",
    "            accuracy = (counts['='] - counts['I']) / (counts['='] + counts['X'] + counts['D'])\n",
    "        else:\n",
    "            accuracy = counts['='] / (counts['='] + counts['I'] + counts['X'] + counts['D'])\n",
    "        return accuracy * 100\n",
    "\n",
    "\n",
    "    def parasail_to_sam(self, result, seq):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L321\n",
    "        \"\"\"\n",
    "        Extract reference start and sam compatible cigar string.\n",
    "\n",
    "        :param result: parasail alignment result.\n",
    "        :param seq: query sequence.\n",
    "\n",
    "        :returns: reference start coordinate, cigar string.\n",
    "        \"\"\"\n",
    "        cigstr = result.cigar.decode.decode()\n",
    "        first = re.search(self.split_cigar, cigstr)\n",
    "\n",
    "        first_count, first_op = first.groups()\n",
    "        prefix = first.group()\n",
    "        rstart = result.cigar.beg_ref\n",
    "        cliplen = result.cigar.beg_query\n",
    "\n",
    "        clip = '' if cliplen == 0 else '{}S'.format(cliplen)\n",
    "        if first_op == 'I':\n",
    "            pre = '{}S'.format(int(first_count) + cliplen)\n",
    "        elif first_op == 'D':\n",
    "            pre = clip\n",
    "            rstart = int(first_count)\n",
    "        else:\n",
    "            pre = '{}{}'.format(clip, prefix)\n",
    "\n",
    "        mid = cigstr[len(prefix):]\n",
    "        end_clip = len(seq) - result.end_query - 1\n",
    "        suf = '{}S'.format(end_clip) if end_clip > 0 else ''\n",
    "        new_cigstr = ''.join((pre, mid, suf))\n",
    "        return rstart, new_cigstr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javila/micromamba/envs/basecalling-cuda117/lib/python3.10/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /home/conda/feedstock_root/build_artifacts/pytorch-recipe_1680572619157/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "Args=namedtuple(\"Args\", [\"path_test\", \"batch_size\", \"model\", \"path_checkpoint\", \"device\"])\n",
    "args = Args(\n",
    "\"../data/subsample_val.hdf5\",\n",
    "16,\n",
    "\"SimpleNet\",\n",
    "\"../output/training/checkpoints/SimpleNet-epoch1.pt\",\n",
    "None,\n",
    ")\n",
    "    \n",
    "PATH_TEST=args.path_test\n",
    "BATCH_SIZE=args.batch_size\n",
    "MODEL=args.model\n",
    "DEVICE=args.device\n",
    "PATH_CHECKPOINT=args.path_checkpoint\n",
    "\n",
    "if DEVICE is None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device = DEVICE\n",
    "print(\"Device\" , device)\n",
    "\n",
    "model=eval(f\"{MODEL}()\")\n",
    "model.to(device)\n",
    "if device.type == \"cpu\":\n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=torch.device('cpu')))\n",
    "else: \n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT))\n",
    "model_output_len = model.output_len\n",
    "\n",
    "# dataset\n",
    "dataset_test = DatasetONT(recfile=PATH_TEST, output_network_len=model_output_len)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_test.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester=BasecallerTester(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    test_loader=dataloader_test,\n",
    "    path_fasta=\"output/testing/basecalled_reads.fa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "# tester.accuracy(\n",
    "seq, ref = (\"ACGTACGTACGTACGAGCAT\",\"ACGACTACGACTACACACAC\")\n",
    "result = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstart, new_cigstr = tester.parasail_to_sam(result, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '4S3=1I2=1I5=4S')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstart, new_cigstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_test))\n",
    "model.eval()\n",
    "X, y, output_len, target_len = (x.to(device) for x in batch)\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, preds.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = {i:c for i,c in zip([1,2,3,4],\"ACGT\")}\n",
    "b = np.apply_along_axis(lambda l: \"\".join([int2char[i] for i in l if i > 0]), 1, y.detach().numpy()) \n",
    "b.shape, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_read(signal, use_viterbi: bool = True, rna: bool = True):\n",
    "    \"Apply viterbi or beam search to a batch\"\n",
    "    alphabet = \"NACGU\" if rna else \"NACGT\"\n",
    "    if use_viterbi is True:\n",
    "        print(\"using viterbi\")\n",
    "        seq, path = viterbi_search(signal, alphabet) \n",
    "    else:\n",
    "        # beam search\n",
    "        print(\"using beam search\")\n",
    "        seq, path = beam_search(signal, alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_signals = preds.detach().numpy()\n",
    "print(batch_signals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_signals.transpose((0,2,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis(signal_to_read, -1, batch_signals.transpose((0,2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[signal_to_read(batch_signals[:,i,:]) for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"NACGT\"\n",
    "posteriors = np.random.rand(100, len(alphabet)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_search(batch_signals[:,0,:], alphabet=\"NACGU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
