{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add parent folder to the path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin libraries\n",
    "import logging\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "# secondary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader # load batches to the network\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "\n",
    "# feito \n",
    "# from basecaller_tester import BasecallerTester as Tester\n",
    "from feito.models import SimpleNet, Rodan\n",
    "from feito.dataloaders.dataloader import DatasetONT\n",
    "from feito.callbacks import CSVLogger, ModelCheckpoint\n",
    "# ---- \n",
    "from collections import namedtuple\n",
    "\n",
    "# types\n",
    "_Path = Union[Path,str]\n",
    "\n",
    "class BasecallerTester:\n",
    "    \n",
    "    def __init__(self, model, device, test_loader, path_fasta: _Path, rna: bool = True, use_viterbi = True):\n",
    "        self.model=model.to(device) \n",
    "        self.device=device\n",
    "        self.test_loader=test_loader # load signals\n",
    "        self.path_fasta=path_fasta # save basecalled raw-reads\n",
    "        self.alphabet=\"NACGU\" if rna else \"NACGT\"\n",
    "        self.search_algo=viterbi_search if use_viterbi  else beam_search\n",
    "\n",
    "    def __call__(self,):\n",
    "        print(\"Que me dice\")\n",
    "        # TODO: implement tester, considering accuracy\n",
    "\n",
    "        # 1. generate output of a signal\n",
    "\n",
    "        # 2. call viterbi or beam search to generate portion of a read\n",
    "        \n",
    "        # 3. send to a fasta file\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def predict_one_batch(self, batch):\n",
    "        \n",
    "        self.model.eval()\n",
    "        X, y, output_len, target_len = (x.to(self.device) for x in batch)\n",
    "        preds  = self.model(X)\n",
    "\n",
    "    def signal_to_read(signal):\n",
    "\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n",
      "CONFIG(vocab=['<PAD>', 'A', 'C', 'G', 'T'], activation='mish', sqex_activation='mish', dropout=0.1, sqex_reduction=32)\n",
      "Activation Function is: mish\n",
      "Activation Function is: mish\n"
     ]
    }
   ],
   "source": [
    "Args=namedtuple(\"Args\", [\"path_test\", \"batch_size\", \"model\", \"path_checkpoint\", \"device\"])\n",
    "args = Args(\n",
    "\"../data/subsample_val.hdf5\",\n",
    "16,\n",
    "\"Rodan\",\n",
    "\"../output/training/checkpoints/Rodan-epoch4.pt\",\n",
    "\"cpu\",\n",
    ")\n",
    "    \n",
    "PATH_TEST=args.path_test\n",
    "BATCH_SIZE=args.batch_size\n",
    "MODEL=args.model\n",
    "DEVICE=args.device\n",
    "PATH_CHECKPOINT=args.path_checkpoint\n",
    "\n",
    "if DEVICE is None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device = DEVICE\n",
    "print(\"Device\" , device)\n",
    "\n",
    "model=eval(f\"{MODEL}()\")\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=torch.device('cpu')))\n",
    "model_output_len = model.output_len\n",
    "\n",
    "# dataset\n",
    "dataset_test = DatasetONT(recfile=PATH_TEST, output_network_len=model_output_len)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Que me dice\n"
     ]
    }
   ],
   "source": [
    "tester=BasecallerTester(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    test_loader=dataloader_test,\n",
    "    path_fasta=\"output/testing/basecalled_reads.fa\"\n",
    ")\n",
    "\n",
    "# inference\n",
    "tester()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dataloader_test))\n",
    "model.eval()\n",
    "X, y, output_len, target_len = (x.to(device) for x in batch)\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 4096]), torch.Size([420, 16, 5]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def signal_to_read(signal):\n",
    "    return torch.Tensor([1,2])\n",
    "\n",
    "\n",
    "axis=1\n",
    "torch.stack([\n",
    "    signal_to_read(signal) for signal in enumerate(torch.unbind(preds, dim=axis), 0)\n",
    "], dim=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0353, -4.3083, -5.3414, -5.8106, -4.3126],\n",
       "         [-0.0493, -3.7497, -4.9249, -4.5319, -5.0215],\n",
       "         [-0.0683, -4.5149, -3.8617, -4.1558, -3.9945],\n",
       "         ...,\n",
       "         [-0.1233, -3.0759, -3.8354, -4.7320, -3.2332],\n",
       "         [-0.0968, -3.8178, -4.1701, -3.3622, -3.9044],\n",
       "         [-0.0645, -4.5514, -3.7699, -5.2649, -3.7413]],\n",
       "\n",
       "        [[-0.0260, -4.8810, -5.4244, -6.4000, -4.4186],\n",
       "         [-0.0526, -3.5151, -5.2983, -4.4369, -5.3726],\n",
       "         [-0.0571, -5.0049, -4.0832, -3.7914, -4.6691],\n",
       "         ...,\n",
       "         [-0.1561, -2.9753, -3.5557, -4.7091, -2.8841],\n",
       "         [-0.0951, -3.4504, -4.4076, -3.4812, -4.1340],\n",
       "         [-0.0738, -4.3499, -3.5965, -4.6835, -3.8352]],\n",
       "\n",
       "        [[-0.0424, -4.6707, -4.8034, -6.2444, -3.8179],\n",
       "         [-0.0763, -2.9426, -6.0223, -4.1446, -5.9987],\n",
       "         [-0.1004, -4.4346, -3.5583, -3.1201, -4.5058],\n",
       "         ...,\n",
       "         [-0.2044, -2.7917, -3.1304, -4.6346, -2.6575],\n",
       "         [-0.0886, -3.8203, -3.9195, -3.9144, -3.7713],\n",
       "         [-0.0663, -3.7928, -4.2937, -4.2140, -4.3288]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1384, -4.0846, -2.7894, -6.2231, -3.0155],\n",
       "         [-0.0307, -6.3699, -4.2200, -7.9097, -4.3052],\n",
       "         [-0.0975, -3.8115, -3.9793, -5.7377, -3.0191],\n",
       "         ...,\n",
       "         [-0.0411, -4.9192, -4.1768, -7.4386, -4.0714],\n",
       "         [-0.0136, -5.8187, -5.7567, -6.9710, -5.0512],\n",
       "         [-0.0306, -5.0818, -4.5221, -8.4931, -4.3548]],\n",
       "\n",
       "        [[-0.0879, -4.4498, -3.1765, -6.7004, -3.5233],\n",
       "         [-0.0294, -6.2093, -4.2367, -8.0241, -4.4061],\n",
       "         [-0.0583, -4.1166, -4.7513, -6.1481, -3.5224],\n",
       "         ...,\n",
       "         [-0.0403, -5.3913, -4.3037, -7.8158, -3.8617],\n",
       "         [-0.0216, -5.9169, -4.9135, -7.7117, -4.5224],\n",
       "         [-0.0371, -5.1357, -4.2009, -8.7381, -4.1766]],\n",
       "\n",
       "        [[-0.0668, -4.4846, -3.7617, -6.3792, -3.5604],\n",
       "         [-0.0219, -5.6912, -4.7016, -8.8449, -4.7088],\n",
       "         [-0.0492, -4.2808, -4.8021, -5.9336, -3.7566],\n",
       "         ...,\n",
       "         [-0.0427, -5.3357, -4.7281, -7.2235, -3.5973],\n",
       "         [-0.0272, -5.8894, -4.6081, -8.3302, -4.2781],\n",
       "         [-0.0465, -4.7852, -4.1322, -8.5496, -3.8721]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2., 2.]]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def signal_to_read(signal):\n",
    "    return torch.Tensor([1,2])\n",
    "\n",
    "np.apply_along_axis(signal_to_read, 1, preds.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
