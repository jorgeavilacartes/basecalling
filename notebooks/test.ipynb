{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add parent folder to the path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin libraries\n",
    "import re\n",
    "import logging\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "\n",
    "# secondary libraries\n",
    "import numpy as np\n",
    "import parasail\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader # load batches to the network\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "from tqdm import tqdm\n",
    "\n",
    "# feito \n",
    "# from basecaller_tester import BasecallerTester as Tester\n",
    "from feito.models import SimpleNet, Rodan\n",
    "from feito.dataloaders.dataloader import DatasetONT\n",
    "# ---- \n",
    "\n",
    "# types\n",
    "_Path = Union[Path,str]\n",
    "\n",
    "class BasecallerTester:\n",
    "    \n",
    "    split_cigar = re.compile(r\"(?P<len>\\d+)(?P<op>\\D+)\")\n",
    "    \n",
    "    def __init__(self, model, device, test_loader, path_fasta: Optional[_Path] = None, rna: bool = True, use_viterbi = True):\n",
    "        self.model  = model.to(device) # model with pretrained weigths loaded\n",
    "        self.device = device\n",
    "        self.test_loader = test_loader # load signals\n",
    "        self.batch_size  = test_loader.batch_size\n",
    "        self.path_fasta  = path_fasta # to save basecalled raw-reads (if not None)\n",
    "        self.rna = rna \n",
    "        self.alphabet    = \"NACGU\" if rna else \"NACGT\"\n",
    "        self.use_viterbi = use_viterbi\n",
    "        self.search_algo = viterbi_search if use_viterbi else beam_search\n",
    "\n",
    "        # set evaluation/inference mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # map integers to characters in the alphabet\n",
    "        self.int2char = {i:c for i,c in enumerate(self.alphabet.replace(\"N\",\"\"), start=1)}\n",
    "\n",
    "    def __call__(self, return_basecalled_signals: bool=True):\n",
    "        print(\"Que me dice\")\n",
    "        # inference\n",
    "        accuracies, basecalled_signals = self.accuracy_all_dataset()\n",
    "\n",
    "        accuracy = np.array(accuracies).mean()\n",
    "\n",
    "        if self.path_fasta:\n",
    "            # create parent directory if it does not exists\n",
    "            Path(self.path_fasta).parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            # save basecalled signals to a fasta file\n",
    "            \n",
    "        \n",
    "        if return_basecalled_signals:\n",
    "            return accuracy, basecalled_signals\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def basecall_one_batch(self, X):\n",
    "        \"Return basecalled signals in the chosen alphabet\"\n",
    "\n",
    "        preds  = self.model(X) # preds shape: (len-signal, item, size-alphabet)\n",
    "        basecalled_signals = list(\n",
    "            self.signal_to_read(signal=preds[:,item,:].detach().numpy(), use_viterbi=self.use_viterbi, rna=self.rna) \n",
    "            for item in range(preds.shape[1])\n",
    "            )\n",
    "\n",
    "        return basecalled_signals\n",
    "\n",
    "    def label_to_alphabet(self, label):\n",
    "        \"Map vector of integers to sequence in DNA or RNA alphabet\"\n",
    "        \n",
    "        return \"\".join([self.int2char[i] for i in label if i > 0])\n",
    "    \n",
    "    def accuracy_one_batch(self, batch):\n",
    "\n",
    "        X, y, output_len, target_len = (x.to(self.device) for x in batch)\n",
    "\n",
    "        basecalled_signals = self.basecall_one_batch(X)\n",
    "        ground_truth = np.apply_along_axis(lambda l: self.label_to_alphabet(l), 1, y.detach().numpy()) \n",
    "        accuracy_batch = [self.accuracy(ref=gt, seq=bs) for gt,bs in zip(basecalled_signals, ground_truth)]\n",
    "        \n",
    "        return accuracy_batch, basecalled_signals\n",
    "    \n",
    "    def accuracy_all_dataset(self,):\n",
    "        \"Returns a list with accuracies and another list with basecalled signals\"\n",
    "        basecalled_signals = []\n",
    "        accuracies = []\n",
    "        n_batches=len(self.test_loader)\n",
    "    \n",
    "        with tqdm(total=n_batches, leave=True, ncols=100, bar_format='{l_bar}{bar}| [{elapsed}{postfix}]') as progress_bar:\n",
    "\n",
    "            for n_batch, batch in enumerate(self.test_loader):\n",
    "\n",
    "                progress_bar.set_description(f\"Evaluating | Batch: {n_batch+1}/{n_batches}\")\n",
    "                accuracy_batch, basecalled_signals_batch = self.accuracy_one_batch(batch)\n",
    "                \n",
    "                accuracies.extend(accuracy_batch)\n",
    "                basecalled_signals.extend(basecalled_signals_batch)\n",
    "                \n",
    "                # progress_bar.set_postfix(train_loss='%.4f' % current_avg_loss)\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        return accuracies, basecalled_signals\n",
    "\n",
    "    def signal_to_read(self, signal, use_viterbi: bool = True, rna: bool = True):\n",
    "        \"Apply viterbi or beam search to a signal\"\n",
    "        \n",
    "        if use_viterbi is True:\n",
    "            seq, path = viterbi_search(signal, self.alphabet) \n",
    "        else:\n",
    "            seq, path = beam_search(signal, self.alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, ref, seq, balanced=False, min_coverage=0.0):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L354\n",
    "        \"\"\"\n",
    "        Calculate the accuracy between `ref` and `seq`\n",
    "        \"\"\"\n",
    "        # alignment = parasail.sw_trace_striped_32(seq, ref, 8, 4, parasail.dnafull) # this crashed, no meaningful error message\n",
    "        alignment = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        q_coverage = len(alignment.traceback.query) / len(seq)\n",
    "        r_coverage = len(alignment.traceback.ref) / len(ref)\n",
    "\n",
    "        if r_coverage < min_coverage:\n",
    "            return 0.0\n",
    "\n",
    "        _, cigar = self.parasail_to_sam(alignment, seq)\n",
    "\n",
    "        for count, op  in re.findall(self.split_cigar, cigar):\n",
    "            counts[op] += int(count)\n",
    "\n",
    "        if balanced:\n",
    "            accuracy = (counts['='] - counts['I']) / (counts['='] + counts['X'] + counts['D'])\n",
    "        else:\n",
    "            accuracy = counts['='] / (counts['='] + counts['I'] + counts['X'] + counts['D'])\n",
    "        return accuracy * 100\n",
    "\n",
    "\n",
    "    def parasail_to_sam(self, result, seq):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L321\n",
    "        \"\"\"\n",
    "        Extract reference start and sam compatible cigar string.\n",
    "\n",
    "        :param result: parasail alignment result.\n",
    "        :param seq: query sequence.\n",
    "\n",
    "        :returns: reference start coordinate, cigar string.\n",
    "        \"\"\"\n",
    "        cigstr = result.cigar.decode.decode()\n",
    "        first = re.search(self.split_cigar, cigstr)\n",
    "\n",
    "        first_count, first_op = first.groups()\n",
    "        prefix = first.group()\n",
    "        rstart = result.cigar.beg_ref\n",
    "        cliplen = result.cigar.beg_query\n",
    "\n",
    "        clip = '' if cliplen == 0 else '{}S'.format(cliplen)\n",
    "        if first_op == 'I':\n",
    "            pre = '{}S'.format(int(first_count) + cliplen)\n",
    "        elif first_op == 'D':\n",
    "            pre = clip\n",
    "            rstart = int(first_count)\n",
    "        else:\n",
    "            pre = '{}{}'.format(clip, prefix)\n",
    "\n",
    "        mid = cigstr[len(prefix):]\n",
    "        end_clip = len(seq) - result.end_query - 1\n",
    "        suf = '{}S'.format(end_clip) if end_clip > 0 else ''\n",
    "        new_cigstr = ''.join((pre, mid, suf))\n",
    "        return rstart, new_cigstr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "Args=namedtuple(\"Args\", [\"path_test\", \"batch_size\", \"model\", \"path_checkpoint\", \"device\"])\n",
    "args = Args(\n",
    "\"../data/subsample_val.hdf5\",\n",
    "16,\n",
    "\"SimpleNet\",\n",
    "\"../output/training/checkpoints/SimpleNet-epoch1.pt\",\n",
    "None,\n",
    ")\n",
    "    \n",
    "PATH_TEST=args.path_test\n",
    "BATCH_SIZE=args.batch_size\n",
    "MODEL=args.model\n",
    "DEVICE=args.device\n",
    "PATH_CHECKPOINT=args.path_checkpoint\n",
    "\n",
    "if DEVICE is None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device = DEVICE\n",
    "print(\"Device\" , device)\n",
    "\n",
    "model=eval(f\"{MODEL}()\")\n",
    "model.to(device)\n",
    "if device.type == \"cpu\":\n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=torch.device('cpu')))\n",
    "else: \n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT))\n",
    "model_output_len = model.output_len\n",
    "\n",
    "# dataset\n",
    "dataset_test = DatasetONT(recfile=PATH_TEST, output_network_len=model_output_len)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_test.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester=BasecallerTester(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    test_loader=dataloader_test,\n",
    "    path_fasta=\"output/testing/basecalled_reads.fa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating | Batch: 13/13: 100%|███████████████████████████████████████████████████████████| [00:02]\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "accuracies, basecalled_signals = tester.accuracy_all_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0,\n",
       " 81.81818181818183,\n",
       " 85.71428571428571,\n",
       " 77.77777777777779,\n",
       " 100.0,\n",
       " 73.33333333333333,\n",
       " 85.71428571428571,\n",
       " 64.70588235294117,\n",
       " 72.72727272727273,\n",
       " 65.0,\n",
       " 87.5,\n",
       " 100.0,\n",
       " 85.71428571428571,\n",
       " 73.91304347826086,\n",
       " 72.72727272727273,\n",
       " 66.66666666666666,\n",
       " 78.57142857142857,\n",
       " 64.70588235294117,\n",
       " 63.63636363636363,\n",
       " 66.66666666666666,\n",
       " 100.0,\n",
       " 66.66666666666666,\n",
       " 75.0,\n",
       " 85.71428571428571,\n",
       " 70.96774193548387,\n",
       " 66.66666666666666,\n",
       " 80.0,\n",
       " 77.77777777777779,\n",
       " 77.77777777777779,\n",
       " 70.0,\n",
       " 100.0,\n",
       " 68.75,\n",
       " 75.0,\n",
       " 62.06896551724138,\n",
       " 87.5,\n",
       " 68.96551724137932,\n",
       " 61.29032258064516,\n",
       " 68.75,\n",
       " 78.57142857142857,\n",
       " 100.0,\n",
       " 62.5,\n",
       " 78.57142857142857,\n",
       " 60.86956521739131,\n",
       " 75.0,\n",
       " 76.47058823529412,\n",
       " 68.0,\n",
       " 70.83333333333334,\n",
       " 87.5,\n",
       " 72.72727272727273,\n",
       " 88.88888888888889,\n",
       " 83.33333333333334,\n",
       " 65.21739130434783,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 71.42857142857143,\n",
       " 90.9090909090909,\n",
       " 86.66666666666667,\n",
       " 77.77777777777779,\n",
       " 77.77777777777779,\n",
       " 70.0,\n",
       " 87.5,\n",
       " 81.81818181818183,\n",
       " 66.66666666666666,\n",
       " 66.66666666666666,\n",
       " 80.0,\n",
       " 58.97435897435898,\n",
       " 61.111111111111114,\n",
       " 100.0,\n",
       " 62.5,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 78.94736842105263,\n",
       " 73.33333333333333,\n",
       " 100.0,\n",
       " 77.77777777777779,\n",
       " 100.0,\n",
       " 81.81818181818183,\n",
       " 68.75,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 64.70588235294117,\n",
       " 70.0,\n",
       " 72.22222222222221,\n",
       " 70.58823529411765,\n",
       " 77.77777777777779,\n",
       " 70.96774193548387,\n",
       " 66.66666666666666,\n",
       " 82.6086956521739,\n",
       " 61.29032258064516,\n",
       " 71.42857142857143,\n",
       " 64.51612903225806,\n",
       " 68.75,\n",
       " 70.73170731707317,\n",
       " 59.183673469387756,\n",
       " 75.0,\n",
       " 83.33333333333334,\n",
       " 88.88888888888889,\n",
       " 100.0,\n",
       " 78.57142857142857,\n",
       " 64.28571428571429,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 78.57142857142857,\n",
       " 76.47058823529412,\n",
       " 69.56521739130434,\n",
       " 62.5,\n",
       " 80.0,\n",
       " 71.42857142857143,\n",
       " 75.0,\n",
       " 100.0,\n",
       " 69.23076923076923,\n",
       " 77.77777777777779,\n",
       " 72.72727272727273,\n",
       " 76.47058823529412,\n",
       " 88.88888888888889,\n",
       " 83.33333333333334,\n",
       " 62.5,\n",
       " 100.0,\n",
       " 70.37037037037037,\n",
       " 91.66666666666666,\n",
       " 57.692307692307686,\n",
       " 87.5,\n",
       " 69.23076923076923,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 76.47058823529412,\n",
       " 72.72727272727273,\n",
       " 65.51724137931035,\n",
       " 68.18181818181817,\n",
       " 68.96551724137932,\n",
       " 73.33333333333333,\n",
       " 81.81818181818183,\n",
       " 70.83333333333334,\n",
       " 76.19047619047619,\n",
       " 73.07692307692307,\n",
       " 85.71428571428571,\n",
       " 65.51724137931035,\n",
       " 71.42857142857143,\n",
       " 72.72727272727273,\n",
       " 100.0,\n",
       " 63.1578947368421,\n",
       " 57.14285714285714,\n",
       " 100.0,\n",
       " 77.77777777777779,\n",
       " 64.28571428571429,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 85.71428571428571,\n",
       " 85.71428571428571,\n",
       " 63.33333333333333,\n",
       " 73.68421052631578,\n",
       " 64.28571428571429,\n",
       " 80.0,\n",
       " 70.37037037037037,\n",
       " 57.692307692307686,\n",
       " 77.77777777777779,\n",
       " 70.37037037037037,\n",
       " 68.42105263157895,\n",
       " 83.33333333333334,\n",
       " 75.0,\n",
       " 62.5,\n",
       " 91.66666666666666,\n",
       " 77.77777777777779,\n",
       " 76.19047619047619,\n",
       " 66.66666666666666,\n",
       " 75.0,\n",
       " 80.0,\n",
       " 100.0,\n",
       " 71.42857142857143,\n",
       " 81.81818181818183,\n",
       " 92.3076923076923,\n",
       " 100.0,\n",
       " 64.0,\n",
       " 73.91304347826086,\n",
       " 100.0,\n",
       " 71.42857142857143,\n",
       " 83.33333333333334,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 100.0,\n",
       " 66.66666666666666,\n",
       " 66.66666666666666,\n",
       " 76.47058823529412,\n",
       " 66.66666666666666,\n",
       " 77.77777777777779,\n",
       " 71.42857142857143,\n",
       " 100.0,\n",
       " 80.0,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 76.19047619047619,\n",
       " 64.28571428571429,\n",
       " 60.60606060606061,\n",
       " 81.81818181818183,\n",
       " 60.71428571428571,\n",
       " 90.0,\n",
       " 68.18181818181817,\n",
       " 66.66666666666666,\n",
       " 75.86206896551724,\n",
       " 66.66666666666666]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGAGAGAGAAGAGAAGAGAGAGAAG',\n",
       " 'GAAGAAAGAAGAGAAAAAAAAAGAAAG',\n",
       " 'AGAAGAGAGAGAGAAGAGAGAGAGAGAGAGAGAGA',\n",
       " 'GAAAGAGAGAAGAGAAAAAAAGAAAG',\n",
       " 'GAGGGAGAAGAGAGGAGAGAGAGAGAGAGAG',\n",
       " 'AGGAGGAGAGGGAAAGAGACGAGAGAGAGAGAGAGAGAAGAGAGGAGAAAAAGAG',\n",
       " 'AGAGAAAGAGAGAAGAGAAAGAAAGAGAGAAGAGAGAGAGAGA',\n",
       " 'AGAGACGAGAGAGGGAGAGAGGAAGGAGAGAGAG',\n",
       " 'AGAGAGAAGAAAGGAAGAGAGAGAAAAG',\n",
       " 'GAGAGAGGAGAGAGAGAAGAGAGAAGAAAA',\n",
       " 'GAGAAGAGAAAGAAGAGAGAGAAGAGA',\n",
       " 'GAGAGAGAGAGGAGAAGAGAAGAAGAGAGAGAAGAAG',\n",
       " 'GAAAAAAAAAGAGAGAGAGAAAGAGAAGACGAGAGAGGG',\n",
       " 'AGAAAGAGAGAGAGAGAAGAGAGAAGAGA',\n",
       " 'GAGAGAAAGAGAGAGAGAAAGAGAAGAGAAGAGAAGAGAGAGAAG',\n",
       " 'GAAGAGAGAGAAAAGAGAGAGAGAGAAGAGAAGAGAGAGAGAGAAGAGAA',\n",
       " 'AGAGAGAAGGAGGGAGAAAGAGAGAGAGAGAAAAAAAGAAGAAG',\n",
       " 'GAGAGAGAGAAAAAGAAGAGAGACGAGAGGAGGGAGAGAG',\n",
       " 'GAGAGAAAGAGAGAGAAAGAAGAGAAAAAG',\n",
       " 'AGAAAGAACGAGAAGAAAAA',\n",
       " 'AAGAGAGAAGAAGAGAGAGAG',\n",
       " 'AGAGAGAGAAAGAAGAGGAAAGAGAAAGAGGAGAGAAGAGAGA',\n",
       " 'GAAGAGAGAGAGAGAGAAAGAGAGAGAGAAAGAGAA',\n",
       " 'GAGAGAAGAGAAGAGAGAGACAGAAAGACGAGAAGAGAGAG',\n",
       " 'AGAAAGGAGAGAAAGAGAGAAGAGAGAGAAGAGAAGAAGAG',\n",
       " 'AGGAGAGAAAGAGGAAAG',\n",
       " 'GAGAAGAGAAAGAAAGAGAGAG',\n",
       " 'AAAGAGAGAGAGAGAGGAGAGAGAAGAAGAAGAGAG',\n",
       " 'GAGAAGAGGGAGAAGAGAGAGAGAAAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAGAGAAGAGAGAGAGAGAAGAGAGAAGAAAGAGAGGG',\n",
       " 'AGAGAAAGAGAGAAGAGAAGAGAGAGAGAGAGAGAGAGGAAA',\n",
       " 'AAAAAAAAGAGAAGAGAAGAGAGAGAGAGAGAGAGAAGAG',\n",
       " 'GAGGAAGAGAGAGAAGAGAGAGAAGAGAGAGAAGAGAGA',\n",
       " 'GAGAAGAGAGAAGAGAGAGAGAGAGACGAAGAGAGAGGAGA',\n",
       " 'AGAAGAAAGAAAAAAAAAGAGAGAGAGAGAAGA',\n",
       " 'AGAGAGAGAAAGAGAGAGGAAGAGAGA',\n",
       " 'AAAAAGAAAGAAGAGAGAGAGAGAGAGAGAGAGAGAAGAGAG',\n",
       " 'AGAGAGAGAGAAAGGAGAAAAGAG',\n",
       " 'GAGAGAAAAGAGAGAGGAGAAGAGAGA',\n",
       " 'AAGAGAGAGAAGAGAGAGAAAGAGAAGAGAGAGAGAGAGAGGAGAGAGAGAG',\n",
       " 'GAAAGAGAAAGAGAGAGAAGAGGAAAGGAGAG',\n",
       " 'GAGAGAGGGAGAGAAGAGAGAGAGAGA',\n",
       " 'AGAGAGAGAAGAGAGAGAAGAGAAGAAAAGAAGAAA',\n",
       " 'GAGAGAAGAAGAGAGAAAAGAGAAGAGGAGAGAGAGAGAGA',\n",
       " 'AGAGAAGAGAAGAGGAGAAGAGAAGAGAGAGAGGAGAGA',\n",
       " 'GAAAGAGAGAGAGAAGAGAGAAGAAGAAGAGAG',\n",
       " 'GAGAGAAGAGAGAGAGAAGGAGAGAG',\n",
       " 'AGAGAAGAGAGAAAGAGAGGAGAGAGAGAGAGA',\n",
       " 'GAGAAGAAAGGAGAAGAAGAGAGAGAAAAAGA',\n",
       " 'AGAGAGAAAAAGAGAAAGAGAGAGAAGAGAAGGAAAAAAAGA',\n",
       " 'GAAAAGAGAAAGAGGAGAAAAAGAGAGAAGAAGGA',\n",
       " 'AGAGAGAGAGGAGGAGAGAGAAAGAGACAGAGAGGAGAGGAA',\n",
       " 'GAGAGAGAAGAGAGAGAGAGAGAGAGAGAGAGA',\n",
       " 'AAAGAGAGAGACAGAGAAGAGAGAGAAAGAGAGAGAAGA',\n",
       " 'GGAGAGAAAAAGAAGAGAGAGAAGAGAGAAGAGA',\n",
       " 'GAGGAAAGAGGAAGAGAAAAAGAGAGA',\n",
       " 'GAGGGAGAGAGAGAGAGAGAGAAAAAGAAGAGAAGAGA',\n",
       " 'AGAGGAAAGAAGAGAAGAGAGAGAGAG',\n",
       " 'GAGAAGAGAAAGAGAGAAAGAGAGAGAGAGAGGAGA',\n",
       " 'GAGAGAGAGAGAGAGGACAGAGAGAAGAGAGAGAG',\n",
       " 'GAGGAAAGGAGAGAGAAGAGAGAAG',\n",
       " 'GAAGAAAAGAGAGAGAGGAGAGAAGAGAAGAGA',\n",
       " 'AGGAGAGAAGAAAGAGAGAGAGAGAGAA',\n",
       " 'AGAAAAGAGAGAGAAGAAGAGAAG',\n",
       " 'AGAGAGAGAAAGAAGAAAAAAGAAGAACG',\n",
       " 'GAGACGAGAAAAGAGAAGGGAGAGAGAGAGGAG',\n",
       " 'AGAGAGAGAGAGAGAAGGAAAGAGAAGAAGAAAAGAGAAGAGAA',\n",
       " 'GAGGAAGAGAAGAGGAGGAGAAAGAAGAGAG',\n",
       " 'GAGAAAGAGAAGGAGAGAGAGAGAGAAGAGAGAA',\n",
       " 'GAGAAAAGAGAGAGAGAGAAAGAGAGAGAAAGAGGAG',\n",
       " 'GAGAGGAGAGAAGAGAGAGAGAGAAAGAAAGAAAGAGAAGAGAG',\n",
       " 'AGAGAGAGAAGGAGAGAAGAGAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAAGAGAGAGAAGAGAGAGAAGAGAGAGAGAAGAAAAAGAGA',\n",
       " 'AGAGAAGAAGGAGAGAGAAAAGAGAGAGAGA',\n",
       " 'AGAGAGAGAGAGAGAGAGAGAGAGAA',\n",
       " 'AGGGAAGAGAGAGAGAGAAAAGAGAGAAGAAGAGA',\n",
       " 'GAGAAAAAAGAGAGAGAG',\n",
       " 'GAAAGGAGAGAGGAGAGAGAGGGGAGAGAGACG',\n",
       " 'AGGAGAGAGAGAGAGAGAGA',\n",
       " 'GAAGAGAGAGAAGAGAGAGAGAAGAAGAGAGAGGAGAAAG',\n",
       " 'AGAGAAAAGAGAGAGAGAAAAGAAAGAGAGGGAGAGAGAGA',\n",
       " 'AAGAGAGAAAGAAGAAGAGAAAAGAAAAGAGAGAGA',\n",
       " 'GAGAAAGAGAGAGAGAGAGAGAAGGAAGAGAGAA',\n",
       " 'GAGAAGAGAGAAGAGAAA',\n",
       " 'GAGAAAAGAGAGAAGAGGAGAGAGAAAAAGAAGAGAGAGA',\n",
       " 'AAAGAAGAGAGAGAAGAGAGAGAGAGGAAA',\n",
       " 'GAGAGAAAGAGAGAGAGAGAGGAGAGAAGAGAAGAG',\n",
       " 'AGAAGAGAGGAGAGAGAGAG',\n",
       " 'GAGGAGAGAGAGAGGAAAGAAAGAGAGAGAAGA',\n",
       " 'AGAGAGAAGAGAAGAGAAGAGAAAAGAGAGAAAGAGAGAA',\n",
       " 'AAGAGAAAAGAGAGAGAGAGAAGGAAGACGAAAAGAGAAAG',\n",
       " 'AAGGAGAGAGGAGAGAAAAGAAAGAAGAGAG',\n",
       " 'AGAGAGAAAGAGGAGAAGAGAGAGAAGAGGAGAGAGAGAGAGAG',\n",
       " 'AGACACAAAAAGAGAGAGAGAGGAGGGAGAGAGGGGGGAG',\n",
       " 'GAGAGAGGAAGAAGGAAAGAGAGAAGAGAAAAG',\n",
       " 'AGAGAGAAGAAAAAAGAGAGAGAG',\n",
       " 'GAGAAAAGAAAGGAAAGAGAGAGAGAGAGGAGAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAAA',\n",
       " 'AGAGAGAGAGAGAAGAGAGAGAAGAGAGAAGA',\n",
       " 'ACGAGAGAGAGAGAAGAGAAGAGAGAGAGAGAGAGAAGAAG',\n",
       " 'GAGAGAAAAAGAGAAAAGAAGAGGGAGAGAAGA',\n",
       " 'GAAGAGAAAGAAGACGAGAGAGAAGAGAAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAGAGAGAAGAAAAGAAGAAG',\n",
       " 'AGGAGGAGAGAAAGAGAGAGAGAGGAGAAGAGGAG',\n",
       " 'AGAGAGAGAGAGAGGAGAGAAGAAAGAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAAGAAAGAA',\n",
       " 'AGAAGAGAAGAAGAGAGAAAAGAGAGAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAAGAAAGAGGAGAGAGAGAGAGAGAGA',\n",
       " 'AAAGAAGAGAGAAAAGGAGAGAGAGAGAGAGA',\n",
       " 'GAGAAAAGAGAAGAAGAGAGAGAGAGAGAGAGAGAGAGAG',\n",
       " 'GAGGGAGAAAGAAGAGAGAAGAGGGGGAGAGAGA',\n",
       " 'AAGAGGAGAGAGAGAGAGAGAAGAGAGAAGAGAAGAAGAAGAGAGA',\n",
       " 'GAGAGAGAGAAAGAGAGAAGGAGAAGAAGAAGAGAGAGAGAGA',\n",
       " 'AGAAGAAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'AGAAGAGAAGAGAGAGAAAAAAAGAGAGAGAGA',\n",
       " 'GAGAAAGAGAGAAAGAGAAG',\n",
       " 'GGAGAAGAAGAGAAGAAGAGAGAG',\n",
       " 'AGAGGAAAGAAGAGAAAGAAAGAGAG',\n",
       " 'AGAAGAAGAGAAGAGAGACGAGGAAGAAGAGAGAG',\n",
       " 'GAAAGAGAGAGGAGAGAGAGGAGAAAGAAGAGAGAAG',\n",
       " 'AGAGAAAGAGAAAGAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAAAGGAGAGAGAGACGAAAAG',\n",
       " 'AAAAGAGAAGAAGAGACAGAAGAG',\n",
       " 'GAGAGAGAAAGAGAAGGAGAGAGAAAGAGAGAGAGAGG',\n",
       " 'GAGAGAGGAGAGAAGAAGGAGAGAGAGAAAGAAGAGAGAGAAACG',\n",
       " 'GAGGAGAGAGAGAGAGACACG',\n",
       " 'GAGAGAGAAAGAGAGGGAAGAGAAAAGGGAAAGAAGAGAAGAG',\n",
       " 'AGAGCGGAAGACGACGAGAAAGAGAGA',\n",
       " 'GAAGAGAAGAGAGAGAGAGAGAAGAGAGAGAGAGA',\n",
       " 'GAAGAGGAGAGAGAGAGGGAGGAAGAGAGAACAGAGAG',\n",
       " 'GGAGAGAGAAAGAGAGAGAGAGAGAGAAAAGAGAGAAGA',\n",
       " 'GAAAGGGAGAAAGAAGAGAGAGAGAGA',\n",
       " 'GAAAGAGAGAGAAAGAGAGAGGAGAGAGAGAGAAG',\n",
       " 'AGAAAGAGAGAGAGAGAGAGAGAGACGAAGAGAAGAG',\n",
       " 'AAGAAGAAGAAAGAAAAGAAAGAAAAGGAGAGAGAAAGAAGAAG',\n",
       " 'GAGAGAAGAGAAGAAAGAGAAGAGAGAGAA',\n",
       " 'AGAGAGAGAGAACGAGAAGAGAAGAGAAGAGGAAG',\n",
       " 'AAGAGAGGGAGAGAAAGAGAAAGAGAG',\n",
       " 'GAGAAAAGAAGAGAAGAAAGGGAAAGA',\n",
       " 'GAGAGAGGAGAAAAAAGAGAGAGAGAGAGAAGAGAGA',\n",
       " 'AAGAGAGAGAAGAGAGAGAGAAGAGAGACGAGAAGAGAGAG',\n",
       " 'AGAGAGAGAGAAGAGAGAGAGGAGAGAGAGAG',\n",
       " 'AAAGAAGAGAAGGAAAGAA',\n",
       " 'AGAAGAGAGAAGAGAAGGAGAGAAAAAA',\n",
       " 'AGAGAAGAGAAGAGAGAGAGAAAGAGAGAGAG',\n",
       " 'GAGAGAGAGAAGAGAAAGAAAAAGAGAGGAGAGAA',\n",
       " 'AGAAAAGAAGAGAGAGAAGAGAAAA',\n",
       " 'AGAGAGAGAAGAGAGAGAGGAGAAGAGAAAGG',\n",
       " 'AGAGAAGAAAAAGAGAGAAAAAGAAGAGAAA',\n",
       " 'GAGAGAGGAAAGAGAGAGAAGAGGAGAGAAGAAGA',\n",
       " 'GAGAGAGAGAGAAGAAGAGAAAGAAAGAGAGAG',\n",
       " 'AGAGAGAGAGAGAGAGAGAGAAAGAGAGAG',\n",
       " 'GAGAAGAGAGAAAAAAGAGAGAGAAAAG',\n",
       " 'GAAGAGAGAGAGAAGAGAGAAGAGAAGAG',\n",
       " 'GAACGGGAAGAAGAGAGAGGAGAGAAAAGA',\n",
       " 'AAGAGAAGAAGAGAGAGAGAGAGAGAGAGAGGAGAG',\n",
       " 'GAAGAAGAGAGAGGGGAGAAGAGAAGAAGAAGAG',\n",
       " 'AGAAAGAGAGAAAGAGGAGA',\n",
       " 'GAAAGAAAGAAGAGAAAGAGAGGAGAGAGAAAG',\n",
       " 'AGAAAAGAGAGAGAGAGGAAGAAGAGAGAGAGAAG',\n",
       " 'GAGAGAGAAGAGAAAGAGAGAGAGAGA',\n",
       " 'AAAAGAGAAGAGAGAGAGAGAGAGAGAAGAGAGAGG',\n",
       " 'GAGAAGAGGAGAGAGAAGAGAGAGGAAGAAGAGAGAGAG',\n",
       " 'AGAGAAGAAGAGAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAGGAGGAGAGAGAGAGAGAGAGAGA',\n",
       " 'AGAAAAGAGAGAAAAGAGAGAGAAGAGAGAGAGAGAGAGA',\n",
       " 'AGAAGAAGAGAGAGAGAAGAGAGAGAGAAG',\n",
       " 'GAGAGAAGAGAAAAAGAGAGAGAGAAAA',\n",
       " 'GAGAGAGAGAGAGAAAGAGGAGAAAGAAGAGAAG',\n",
       " 'GAGAAGAGAGAGAAGAGAGAGAGAGAGAGAGAAGAGAGAAAG',\n",
       " 'AGAGGAGAGAGA',\n",
       " 'GAGAGAGAAAAGAAAGAA',\n",
       " 'AGAGAAAAAGAAAGAGAGAGAGAGAAAGAGAAGAA',\n",
       " 'AGAGAGAAAGAGAGAGAGAAGGAAGAGAGGA',\n",
       " 'GAGGAGAAGAGAAAGGAGAGAAGAGAGAGAGAGAGA',\n",
       " 'AAAAGAGAGGAGAGAGAGAGAGA',\n",
       " 'AGAGAAAAGAAAAGAAAAAAAAAAAA',\n",
       " 'GAGAGAGAGAGAAGAGAGAGAGAGAAGAGAG',\n",
       " 'AGAAGGGAAGAAGAGAGAAGAGAGAAGGAGAGAAGAGA',\n",
       " 'GAAGAAGAAGAGAGAAGAGAGAGAGGAGAGAGAGAGAGAGAGAAA',\n",
       " 'AGAGAGAAGAGAGAAAAGGAGAAAAGAGAGAGAAGGAGAGAGAGAGAGG',\n",
       " 'GAGAAAAGGAGAAGAAAGAAGAAGAGGAGAGAGAGAA',\n",
       " 'AGAGAGAAAAGAGAAGAGAGAAGAGAGAGAGAAG',\n",
       " 'AGAAAGAGAGAAGAGAAGAAG',\n",
       " 'GAGAGAGAGAGAAGAGAGAAAGAGAGAGAGAGAAGAA',\n",
       " 'GAGAGAAGAGAGAGAAGAAGAGAGAGGAAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAAGAAGAGAGAGAGAGGAGAAAAAAGA',\n",
       " 'GAAGAGAGAAGAGAGAGAGAAGAGAAAAGAGAGAG',\n",
       " 'GAAGGAGAAAAAGAGAAGAGAAAGAGGAG',\n",
       " 'AGAGAGAAGGAGAGAGAGAGA',\n",
       " 'GAGAAAGAGAAGAGAGAGAGAGGAGAGAAG',\n",
       " 'AGAGAGGAGAAGAAAAAGAGAGGAAGAGAGAGAGAGAGAAGAAG',\n",
       " 'GAGGAGGAAGAGAGAGAGAGAGAGAAGAGAGAGAGGAGAGAGAG',\n",
       " 'AAGAGAGAGAAGAGAAGAGAGAGAGAAGAGAAAA',\n",
       " 'GAGAGAGAAAAGAGAGAGACGAAGAGAGAAGAGA',\n",
       " 'GGAGAAAGAAGAGAGAGAGAAGAGAAGAGAGAAAGGAGAGA',\n",
       " 'GAGAGAGAGGAGAGAGAGAGAGAGAAAAAAGGAGAAGAGA',\n",
       " 'AAGAGAAAGAGGAGAGAGAAGGAGGAGG',\n",
       " 'GAGAGAAGAGAGAGAGAAGAGAGAGAAGAGAG',\n",
       " 'AGAAGAAGAAGAGAGAGAGA']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basecalled_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"../output/test/basecalled_signals.fa\"\n",
    "Path(path_fasta).parent.mkdir(exist_ok=True, parents=True)\n",
    "with open(path_fasta, \"a\") as fp:\n",
    "    for j,read in enumerate(basecalled_signals):\n",
    "        fp.write(f\">signal_{j}\\n\")\n",
    "        fp.write(read + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, ref = (\"ACGTACGTACGTACGAGCAT\",\"ACGACTACGACTACACACAC\")\n",
    "result = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstart, new_cigstr = tester.parasail_to_sam(result, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '4S3=1I2=1I5=4S')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstart, new_cigstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_test))\n",
    "model.eval()\n",
    "X, y, output_len, target_len = (x.to(device) for x in batch)\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 4096]), torch.Size([501, 16, 5]), torch.Size([16, 271]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, preds.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 16, 5)\n"
     ]
    }
   ],
   "source": [
    "batch_signals = preds.detach().numpy()\n",
    "print(batch_signals.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
