{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# add parent folder to the path\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builtin libraries\n",
    "import re\n",
    "import logging\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "from collections import namedtuple, defaultdict\n",
    "from functools import partial\n",
    "\n",
    "# secondary libraries\n",
    "import numpy as np\n",
    "import parasail\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader # load batches to the network\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "from tqdm import tqdm\n",
    "\n",
    "# feito \n",
    "# from basecaller_tester import BasecallerTester as Tester\n",
    "from feito.models import SimpleNet, Rodan\n",
    "from feito.dataloaders import DatasetONT, DatasetBasecalling\n",
    "from feito.api.tester import BasecallerTester\n",
    "# ---- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG(vocab=['<PAD>', 'A', 'C', 'G', 'T'], activation='mish', sqex_activation='mish', dropout=0.1, sqex_reduction=32)\n",
      "Activation Function is: mish\n",
      "Activation Function is: mish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Rodan(\n",
       "  (convlayers): Sequential(\n",
       "    (conv0): ConvBlockRodan(\n",
       "      (conv): Conv1d(1, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv1): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(256, 256, kernel_size=(10,), stride=(1,), padding=(5,), groups=256, bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv2): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(256, 256, kernel_size=(10,), stride=(10,), padding=(5,), groups=256, bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv3): ConvBlockRodan(\n",
       "      (expansion): Conv1d(256, 320, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (expansion_norm): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (expansion_act): Mish()\n",
       "      (depthwise): Conv1d(320, 320, kernel_size=(10,), stride=(1,), padding=(5,), groups=320, bias=False)\n",
       "      (bn1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=320, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=320, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(320, 320, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv4): ConvBlockRodan(\n",
       "      (expansion): Conv1d(320, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (expansion_norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (expansion_act): Mish()\n",
       "      (depthwise): Conv1d(384, 384, kernel_size=(15,), stride=(1,), padding=(7,), groups=384, bias=False)\n",
       "      (bn1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=384, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=384, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(384, 384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv5): ConvBlockRodan(\n",
       "      (expansion): Conv1d(384, 448, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (expansion_norm): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (expansion_act): Mish()\n",
       "      (depthwise): Conv1d(448, 448, kernel_size=(20,), stride=(1,), padding=(10,), groups=448, bias=False)\n",
       "      (bn1): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=448, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=448, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(448, 448, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv6): ConvBlockRodan(\n",
       "      (expansion): Conv1d(448, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (expansion_norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (expansion_act): Mish()\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(25,), stride=(1,), padding=(12,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv7): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(30,), stride=(1,), padding=(15,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv8): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(35,), stride=(1,), padding=(17,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv9): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(40,), stride=(1,), padding=(20,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv10): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(45,), stride=(1,), padding=(22,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv11): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(512, 512, kernel_size=(50,), stride=(1,), padding=(25,), groups=512, bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(512, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv12): ConvBlockRodan(\n",
       "      (expansion): Conv1d(512, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (expansion_norm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (expansion_act): Mish()\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(55,), stride=(1,), padding=(27,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv13): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(60,), stride=(1,), padding=(30,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv14): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(65,), stride=(1,), padding=(32,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv15): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(70,), stride=(1,), padding=(35,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv16): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(75,), stride=(1,), padding=(37,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv17): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(80,), stride=(1,), padding=(40,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv18): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(85,), stride=(1,), padding=(42,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv19): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(90,), stride=(1,), padding=(45,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv20): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(95,), stride=(1,), padding=(47,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (conv21): ConvBlockRodan(\n",
       "      (depthwise): Conv1d(768, 768, kernel_size=(100,), stride=(1,), padding=(50,), groups=768, bias=False)\n",
       "      (bn1): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): Mish()\n",
       "      (sqex): SqueezeExcite(\n",
       "        (avg): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
       "        (activation): Mish()\n",
       "        (fc2): Linear(in_features=32, out_features=768, bias=True)\n",
       "        (sigmoid): Sigmoid()\n",
       "      )\n",
       "      (pointwise): Conv1d(768, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): Mish()\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL=\"Rodan\"\n",
    "PATH_CHECKPOINT=\"../output-rodan/training/checkpoints/Rodan-epoch29.pt\"\n",
    "BATCH_SIZE=8\n",
    "NUM_WORKERS=4\n",
    "device=torch.device(\"cpu\")\n",
    "\n",
    "model=eval(f\"{MODEL}()\")\n",
    "model.to(device)\n",
    "if device.type == \"cpu\":\n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=torch.device('cpu')))\n",
    "else: \n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT))\n",
    "\n",
    "model_output_len=model.output_len\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Try with hdf5 files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST=\"../data/subsample_val.hdf5\"\n",
    "\n",
    "# dataset\n",
    "dataset_test = DatasetONT(recfile=PATH_TEST, output_network_len=model_output_len)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y, input_lens , target_lens  = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8231, -0.8631, -0.7259,  ..., -1.0803, -1.1375, -1.1318]],\n",
       "\n",
       "        [[-1.1146, -1.1318, -1.0918,  ..., -0.3658, -0.1658, -0.2801]],\n",
       "\n",
       "        [[-0.4973, -0.2401, -0.3144,  ...,  0.4744,  0.4573,  0.6345]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4417, -0.7461, -0.6864,  ..., -0.3880, -0.2865, -0.4119]],\n",
       "\n",
       "        [[-0.2865, -0.1492, -0.4119,  ..., -0.0478,  0.2686,  0.2328]],\n",
       "\n",
       "        [[ 0.1970,  0.2089,  0.1552,  ..., -0.3820, -0.2149,  0.0716]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 4096]),\n",
       " torch.Size([8, 271]),\n",
       " torch.Size([8]),\n",
       " torch.Size([8]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape , input_lens.shape, target_lens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.0028e-02, -4.3367e+00, -4.6725e+00, -3.4958e+00, -5.2015e+00],\n",
       "         [-1.0876e-02, -5.4211e+00, -6.4891e+00, -5.6675e+00, -6.5578e+00],\n",
       "         [-1.7277e-02, -4.7086e+00, -6.0435e+00, -6.7250e+00, -5.3955e+00],\n",
       "         ...,\n",
       "         [-3.3899e-02, -3.9264e+00, -5.9860e+00, -4.9651e+00, -5.4905e+00],\n",
       "         [-2.0324e-02, -5.5067e+00, -5.9351e+00, -4.4076e+00, -6.7003e+00],\n",
       "         [-2.4959e-02, -4.8906e+00, -5.2342e+00, -4.7601e+00, -5.7331e+00]],\n",
       "\n",
       "        [[-6.1985e-02, -4.3117e+00, -4.7206e+00, -3.4071e+00, -5.3717e+00],\n",
       "         [-1.2549e-02, -5.2570e+00, -6.3048e+00, -5.5417e+00, -6.4945e+00],\n",
       "         [-1.7589e-02, -4.5786e+00, -5.9410e+00, -6.5581e+00, -5.7705e+00],\n",
       "         ...,\n",
       "         [-5.4407e-02, -3.2913e+00, -6.2717e+00, -4.5012e+00, -5.8914e+00],\n",
       "         [-2.2678e-02, -5.8233e+00, -5.5463e+00, -4.2953e+00, -6.2500e+00],\n",
       "         [-2.8894e-02, -4.5379e+00, -5.1566e+00, -4.7875e+00, -5.6021e+00]],\n",
       "\n",
       "        [[-7.3424e-02, -4.4914e+00, -3.9847e+00, -3.4179e+00, -4.8025e+00],\n",
       "         [-1.8892e-02, -4.8819e+00, -5.8310e+00, -5.0829e+00, -6.2170e+00],\n",
       "         [-1.5713e-02, -4.6169e+00, -6.4168e+00, -6.8267e+00, -5.8130e+00],\n",
       "         ...,\n",
       "         [-7.3613e-02, -2.9049e+00, -7.0534e+00, -4.2961e+00, -6.3616e+00],\n",
       "         [-2.3281e-02, -5.8780e+00, -5.9454e+00, -4.1581e+00, -6.2362e+00],\n",
       "         [-3.6829e-02, -4.0130e+00, -5.1652e+00, -4.9596e+00, -5.2301e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-9.2835e-03, -6.9493e+00, -5.9787e+00, -8.1993e+00, -5.2077e+00],\n",
       "         [-5.3903e-02, -4.1035e+00, -4.4203e+00, -6.1848e+00, -3.8227e+00],\n",
       "         [-6.0557e-03, -7.7677e+00, -6.3638e+00, -8.5686e+00, -5.5990e+00],\n",
       "         ...,\n",
       "         [-3.4052e-02, -5.1261e+00, -4.7405e+00, -6.6826e+00, -4.0425e+00],\n",
       "         [-6.9602e-02, -5.0272e+00, -4.3482e+00, -3.5332e+00, -3.9881e+00],\n",
       "         [-6.4381e-03, -7.1815e+00, -5.9601e+00, -7.7710e+00, -5.9311e+00]],\n",
       "\n",
       "        [[-1.0808e-02, -6.2613e+00, -5.9894e+00, -7.6501e+00, -5.1396e+00],\n",
       "         [-3.1543e-02, -4.6998e+00, -4.9018e+00, -6.4734e+00, -4.3447e+00],\n",
       "         [-9.0841e-03, -7.6257e+00, -6.1597e+00, -8.2852e+00, -5.0848e+00],\n",
       "         ...,\n",
       "         [-2.8789e-02, -5.3588e+00, -4.8422e+00, -6.5894e+00, -4.2400e+00],\n",
       "         [-6.5554e-02, -5.0825e+00, -3.9877e+00, -4.2716e+00, -3.6991e+00],\n",
       "         [-9.0046e-03, -6.5585e+00, -5.5502e+00, -7.3510e+00, -5.8034e+00]],\n",
       "\n",
       "        [[-7.4911e-03, -6.1633e+00, -6.5776e+00, -8.0188e+00, -5.6165e+00],\n",
       "         [-3.2394e-02, -4.9734e+00, -4.6669e+00, -6.5455e+00, -4.2603e+00],\n",
       "         [-1.5787e-02, -6.6820e+00, -5.5750e+00, -8.0803e+00, -4.5747e+00],\n",
       "         ...,\n",
       "         [-2.0722e-02, -5.6461e+00, -5.2012e+00, -6.5522e+00, -4.6011e+00],\n",
       "         [-5.4995e-02, -5.1638e+00, -4.1983e+00, -5.0664e+00, -3.6320e+00],\n",
       "         [-9.7848e-03, -6.1417e+00, -5.5702e+00, -6.9634e+00, -5.8674e+00]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-51.3859, grad_fn=<MinBackward1>), tensor(0., grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.min(), pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.4174e-01, 1.3080e-02, 9.3486e-03, 3.0325e-02, 5.5083e-03],\n",
       "         [9.8918e-01, 4.4222e-03, 1.5199e-03, 3.4564e-03, 1.4190e-03],\n",
       "         [9.8287e-01, 9.0176e-03, 2.3733e-03, 1.2005e-03, 4.5370e-03],\n",
       "         ...,\n",
       "         [9.6667e-01, 1.9714e-02, 2.5137e-03, 6.9770e-03, 4.1258e-03],\n",
       "         [9.7988e-01, 4.0596e-03, 2.6448e-03, 1.2184e-02, 1.2305e-03],\n",
       "         [9.7535e-01, 7.5169e-03, 5.3311e-03, 8.5650e-03, 3.2371e-03]],\n",
       "\n",
       "        [[9.3990e-01, 1.3411e-02, 8.9102e-03, 3.3136e-02, 4.6463e-03],\n",
       "         [9.8753e-01, 5.2109e-03, 1.8276e-03, 3.9199e-03, 1.5118e-03],\n",
       "         [9.8256e-01, 1.0269e-02, 2.6293e-03, 1.4186e-03, 3.1182e-03],\n",
       "         ...,\n",
       "         [9.4705e-01, 3.7206e-02, 1.8890e-03, 1.1096e-02, 2.7630e-03],\n",
       "         [9.7758e-01, 2.9578e-03, 3.9019e-03, 1.3633e-02, 1.9305e-03],\n",
       "         [9.7152e-01, 1.0696e-02, 5.7614e-03, 8.3337e-03, 3.6902e-03]],\n",
       "\n",
       "        [[9.2921e-01, 1.1205e-02, 1.8598e-02, 3.2781e-02, 8.2091e-03],\n",
       "         [9.8129e-01, 7.5825e-03, 2.9351e-03, 6.2020e-03, 1.9951e-03],\n",
       "         [9.8441e-01, 9.8833e-03, 1.6339e-03, 1.0844e-03, 2.9886e-03],\n",
       "         ...,\n",
       "         [9.2903e-01, 5.4757e-02, 8.6450e-04, 1.3621e-02, 1.7267e-03],\n",
       "         [9.7699e-01, 2.8004e-03, 2.6179e-03, 1.5637e-02, 1.9572e-03],\n",
       "         [9.6384e-01, 1.8079e-02, 5.7119e-03, 7.0155e-03, 5.3531e-03]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[9.9076e-01, 9.5929e-04, 2.5322e-03, 2.7485e-04, 5.4742e-03],\n",
       "         [9.4752e-01, 1.6516e-02, 1.2030e-02, 2.0605e-03, 2.1869e-02],\n",
       "         [9.9396e-01, 4.2318e-04, 1.7228e-03, 1.8998e-04, 3.7015e-03],\n",
       "         ...,\n",
       "         [9.6652e-01, 5.9396e-03, 8.7339e-03, 1.2525e-03, 1.7553e-02],\n",
       "         [9.3277e-01, 6.5573e-03, 1.2930e-02, 2.9212e-02, 1.8535e-02],\n",
       "         [9.9358e-01, 7.6054e-04, 2.5796e-03, 4.2180e-04, 2.6556e-03]],\n",
       "\n",
       "        [[9.8925e-01, 1.9087e-03, 2.5052e-03, 4.7601e-04, 5.8601e-03],\n",
       "         [9.6895e-01, 9.0974e-03, 7.4333e-03, 1.5440e-03, 1.2976e-02],\n",
       "         [9.9096e-01, 4.8777e-04, 2.1128e-03, 2.5222e-04, 6.1902e-03],\n",
       "         ...,\n",
       "         [9.7162e-01, 4.7067e-03, 7.8900e-03, 1.3749e-03, 1.4407e-02],\n",
       "         [9.3655e-01, 6.2046e-03, 1.8543e-02, 1.3959e-02, 2.4745e-02],\n",
       "         [9.9104e-01, 1.4180e-03, 3.8869e-03, 6.4195e-04, 3.0173e-03]],\n",
       "\n",
       "        [[9.9254e-01, 2.1052e-03, 1.3912e-03, 3.2921e-04, 3.6375e-03],\n",
       "         [9.6812e-01, 6.9197e-03, 9.4014e-03, 1.4365e-03, 1.4118e-02],\n",
       "         [9.8434e-01, 1.2532e-03, 3.7913e-03, 3.0957e-04, 1.0309e-02],\n",
       "         ...,\n",
       "         [9.7949e-01, 3.5313e-03, 5.5099e-03, 1.4269e-03, 1.0041e-02],\n",
       "         [9.4649e-01, 5.7199e-03, 1.5022e-02, 6.3052e-03, 2.6464e-02],\n",
       "         [9.9026e-01, 2.1512e-03, 3.8099e-03, 9.4586e-04, 2.8302e-03]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(pred, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 3, 2, 4, 3, 2, 4, 1, 4, 1, 3, 2, 1, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2,\n",
       "        2, 2, 2, 4, 3, 2, 3, 2, 4, 2, 3, 4, 2, 4, 4, 4, 3, 3, 1, 2, 2, 1, 2, 3,\n",
       "        1, 2, 2, 4, 1, 1, 3, 1, 2, 4, 3, 4, 3, 3, 4, 1, 2, 2, 4, 4, 1, 2, 4, 4,\n",
       "        2, 4, 3, 2, 4, 4, 2, 1, 1, 2, 4, 4, 2, 1, 3, 2, 3, 3, 2, 4, 4, 2, 3, 4,\n",
       "        2, 1, 1, 3, 3, 1, 3, 1, 4, 3, 2, 4, 4, 4, 4, 4, 1, 3, 2, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 4, 4, 0, 4, 3, 3, 0, 0, 0, 0, 0, 2,\n",
       "        3, 3, 0, 0, 0, 0, 4, 4, 0, 4, 1, 1, 0, 0, 0, 0, 4, 1, 1, 3, 3, 0, 0, 0,\n",
       "        0, 2, 4, 1, 1, 3, 3, 3, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 0, 4, 4, 3, 3, 0, 0, 0, 0, 0, 4, 3,\n",
       "        3, 3, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 3, 0, 0, 0,\n",
       "        0, 0, 0, 4, 4, 0, 0, 0, 0, 4, 4, 0, 0, 4, 4, 3, 3, 0, 0, 0, 3, 3, 0, 0,\n",
       "        0, 0, 1, 2, 2, 2, 0, 0, 4, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 2, 2, 2, 2, 2,\n",
       "        2, 0, 0, 0, 0, 0, 0, 4, 4, 1, 1, 1, 0, 0, 1, 1, 3, 3, 3, 0, 0, 0, 3, 2,\n",
       "        2, 0, 2, 4, 3, 3, 0, 0, 0, 4, 4, 3, 3, 3, 0, 0, 3, 3, 0, 4, 4, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 4, 3, 3, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2,\n",
       "        2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 1, 1, 3, 3, 0, 0, 0, 2, 2,\n",
       "        3, 3, 3, 0, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 4, 0, 0, 2, 2, 3, 3, 0, 0,\n",
       "        0, 0, 0, 4, 4, 4, 4, 2, 2, 1, 1, 0, 0, 1, 1, 3, 3, 3, 3, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 1, 3, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(pred, dim=-1).argmax(dim=2)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try with fast5 files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creatind Index for reads:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creatind Index for reads: 100%|██████████| 2/2 [00:00<00:00,  3.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_basecalling = DatasetBasecalling(\n",
    "    [\"/projects5/basecalling-jorge/basecalling/data/RODAN/test/mouse-dataset/0/0a0bf68b-3b64-4fc6-ba34-d853db589f4b.fast5\",\n",
    "     \"/projects5/basecalling-jorge/basecalling/data/RODAN/test/mouse-dataset/0/0a8787dc-a4b9-45da-b4e0-8711ec36897e.fast5\"\n",
    "     ], path_save_index=\"../output/basecalling/index.csv\")\n",
    "basecalling_dataloader = DataLoader(dataset_basecalling, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 4096])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = next(iter(basecalling_dataloader))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.3039e-03, -7.0188e+00, -8.3547e+00, -9.4399e+00, -6.8200e+00],\n",
       "         [-6.3417e-05, -1.1120e+01, -1.4007e+01, -1.2508e+01, -1.0030e+01],\n",
       "         [-6.0873e-02, -4.1004e+00, -4.5835e+00, -4.5066e+00, -3.8520e+00],\n",
       "         ...,\n",
       "         [-5.4221e-03, -6.8140e+00, -6.5006e+00, -8.5874e+00, -5.9445e+00],\n",
       "         [-4.1723e-06, -1.3853e+01, -1.6901e+01, -1.5875e+01, -1.2671e+01],\n",
       "         [-1.1572e-01, -3.0363e+00, -3.9706e+00, -5.1144e+00, -3.3134e+00]],\n",
       "\n",
       "        [[-1.6385e-03, -7.5275e+00, -8.5046e+00, -9.7650e+00, -7.0832e+00],\n",
       "         [-5.3643e-05, -1.1421e+01, -1.4264e+01, -1.2837e+01, -1.0140e+01],\n",
       "         [-9.0112e-02, -4.1333e+00, -3.9173e+00, -4.9427e+00, -3.1440e+00],\n",
       "         ...,\n",
       "         [-5.5851e-03, -6.5755e+00, -6.5116e+00, -8.5503e+00, -5.9932e+00],\n",
       "         [-4.6492e-06, -1.3574e+01, -1.7253e+01, -1.5772e+01, -1.2639e+01],\n",
       "         [-1.3911e-01, -2.8214e+00, -4.2555e+00, -4.5428e+00, -3.0897e+00]],\n",
       "\n",
       "        [[-1.1274e-03, -8.0260e+00, -8.6139e+00, -1.0201e+01, -7.4503e+00],\n",
       "         [-4.7683e-05, -1.1472e+01, -1.4479e+01, -1.3073e+01, -1.0268e+01],\n",
       "         [-1.4170e-01, -4.2710e+00, -3.4229e+00, -5.5324e+00, -2.5062e+00],\n",
       "         ...,\n",
       "         [-5.9611e-03, -6.1678e+00, -6.6473e+00, -8.4826e+00, -6.0563e+00],\n",
       "         [-3.4571e-06, -1.3465e+01, -1.8221e+01, -1.5986e+01, -1.3196e+01],\n",
       "         [-1.5216e-01, -2.6838e+00, -4.1455e+00, -4.1688e+00, -3.1811e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.9947e-02, -4.7796e+00, -5.4017e+00, -6.0557e+00, -4.2510e+00],\n",
       "         [-6.7765e-02, -4.2870e+00, -3.9327e+00, -6.0215e+00, -3.5147e+00],\n",
       "         [-1.6403e-02, -4.8771e+00, -5.9942e+00, -6.3016e+00, -5.4438e+00],\n",
       "         ...,\n",
       "         [-5.2007e-02, -5.8325e+00, -4.2217e+00, -7.2476e+00, -3.4308e+00],\n",
       "         [-1.0131e-02, -6.7917e+00, -5.7046e+00, -8.7684e+00, -5.2083e+00],\n",
       "         [-5.5815e-02, -4.4534e+00, -4.0341e+00, -5.7691e+00, -3.8248e+00]],\n",
       "\n",
       "        [[-4.1648e-02, -4.6615e+00, -5.2001e+00, -5.9343e+00, -3.7646e+00],\n",
       "         [-5.8788e-02, -4.3832e+00, -4.4048e+00, -6.1303e+00, -3.4994e+00],\n",
       "         [-9.0525e-03, -5.8306e+00, -6.3652e+00, -7.7176e+00, -5.5442e+00],\n",
       "         ...,\n",
       "         [-5.1947e-02, -5.6795e+00, -4.2304e+00, -6.7548e+00, -3.4580e+00],\n",
       "         [-8.4232e-03, -7.2877e+00, -5.9794e+00, -9.4747e+00, -5.2792e+00],\n",
       "         [-2.9304e-02, -4.7597e+00, -4.6722e+00, -7.3444e+00, -4.5744e+00]],\n",
       "\n",
       "        [[-5.4299e-02, -4.5106e+00, -5.0256e+00, -5.7660e+00, -3.4371e+00],\n",
       "         [-5.5428e-02, -3.9196e+00, -4.6468e+00, -6.1446e+00, -3.8017e+00],\n",
       "         [-7.8279e-03, -6.1063e+00, -6.5064e+00, -7.9987e+00, -5.5890e+00],\n",
       "         ...,\n",
       "         [-4.2783e-02, -5.5266e+00, -4.6840e+00, -6.4434e+00, -3.6094e+00],\n",
       "         [-1.3488e-02, -6.9828e+00, -5.6375e+00, -8.7803e+00, -4.7383e+00],\n",
       "         [-2.5862e-02, -4.6490e+00, -4.9812e+00, -7.2163e+00, -4.7844e+00]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predb = model(X)\n",
    "predb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-29.9956, grad_fn=<MinBackward1>), tensor(0., grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predb.min(), predb.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9770e-01, 8.9490e-04, 2.3528e-04, 7.9492e-05, 1.0917e-03],\n",
       "        [9.9836e-01, 5.3806e-04, 2.0254e-04, 5.7429e-05, 8.3907e-04],\n",
       "        [9.9887e-01, 3.2685e-04, 1.8156e-04, 3.7140e-05, 5.8124e-04],\n",
       "        ...,\n",
       "        [9.7050e-01, 8.3990e-03, 4.5087e-03, 2.3445e-03, 1.4250e-02],\n",
       "        [9.5921e-01, 9.4525e-03, 5.5158e-03, 2.6470e-03, 2.3177e-02],\n",
       "        [9.4715e-01, 1.0992e-02, 6.5677e-03, 3.1322e-03, 3.2159e-02]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(predb[:,0,:], dim=-1)# .sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3, 3, 3, 0, 0, 0, 3, 3, 3, 3, 0, 4,\n",
       "        4, 0, 2, 3, 3, 0, 0, 0, 0, 0, 2, 2, 3, 3, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0,\n",
       "        0, 2, 2, 0, 2, 2, 3, 3, 0, 0, 3, 2, 2, 2, 2, 3, 0, 0, 0, 1, 1, 0, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 2, 2, 3, 0, 0, 0, 0, 4, 0, 4, 1, 3,\n",
       "        3, 0, 0, 0, 1, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        4, 4, 4, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 3, 0, 0,\n",
       "        0, 0, 4, 4, 0, 1, 1, 0, 0, 0, 4, 0, 0, 4, 3, 3, 0, 0, 2, 2, 0, 0, 0, 0,\n",
       "        0, 0, 4, 4, 0, 2, 2, 1, 0, 0, 0, 0, 1, 1, 1, 3, 3, 0, 0, 0, 0, 2, 2, 2,\n",
       "        0, 0, 2, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 3, 3, 0, 0, 0, 0, 0, 0, 4,\n",
       "        4, 0, 4, 4, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 2, 2, 3, 3, 0, 1, 1, 1, 3, 3,\n",
       "        3, 3, 3, 3, 2, 2, 2, 0, 0, 2, 2, 3, 3, 3, 0, 1, 1, 2, 2, 4, 0, 0, 4, 3,\n",
       "        3, 0, 0, 0, 0, 2, 2, 1, 3, 3, 0, 0, 0, 0, 0, 0, 2, 3, 3, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 4, 4, 1, 1, 0, 0, 0, 1, 1, 3, 3, 3, 3, 0, 0, 4, 4, 0, 0,\n",
       "        0, 0, 1, 1, 3, 3, 3, 4, 4, 4, 0, 0, 0, 0, 4, 4, 3, 3, 0, 0, 1, 1, 2, 2,\n",
       "        0, 0, 2, 2, 2, 3, 3, 3, 0, 0, 4, 1, 0, 0, 0, 3, 3, 3, 3, 0, 0, 2, 2, 0,\n",
       "        0, 2, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 2, 4, 1, 1,\n",
       "        3, 3, 3, 0, 0, 1, 1, 3, 3, 3, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(predb, dim=-1).argmax(dim=2)[:,3] #.sum(axis=2)\n",
    "# torch.sum(\n",
    "#     torch.softmax(predb, dim=-1)\n",
    "#           , dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.argmax(predb.detach().numpy(), -1), (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Ran out of search space (beam_cut_threshold too high)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# signal = torch.softmax(predb[:,item,:], dim=-1).detach().numpy()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m signal \u001b[39m=\u001b[39m predb[:,item,:]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m----> 4\u001b[0m seq , path \u001b[39m=\u001b[39m beam_search( signal, \u001b[39m\"\u001b[39;49m\u001b[39mNACGT\u001b[39;49m\u001b[39m\"\u001b[39;49m, beam_size\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, beam_cut_threshold\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m seq\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Ran out of search space (beam_cut_threshold too high)"
     ]
    }
   ],
   "source": [
    "item = 0\n",
    "# signal = torch.softmax(predb[:,item,:], dim=-1).detach().numpy()\n",
    "signal = predb[:,item,:].detach().numpy()\n",
    "seq , path = beam_search( signal, \"NACGT\", beam_size=5, beam_cut_threshold=0.1)\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# types\n",
    "_Path = Union[Path,str]\n",
    "\n",
    "class BasecallerTester:\n",
    "    \n",
    "    split_cigar = re.compile(r\"(?P<len>\\d+)(?P<op>\\D+)\")\n",
    "    \n",
    "    def __init__(self, model, device, test_loader, path_fasta: Optional[_Path] = None, rna: bool = True, use_viterbi = True):\n",
    "        self.model  = model.to(device) # model with pretrained weigths loaded\n",
    "        self.device = device\n",
    "        self.test_loader = test_loader # load signals\n",
    "        self.batch_size  = test_loader.batch_size\n",
    "        self.path_fasta  = path_fasta # to save basecalled raw-reads (if not None)\n",
    "        self.rna = rna \n",
    "        self.alphabet    = \"NACGU\" if rna else \"NACGT\"\n",
    "        self.use_viterbi = use_viterbi\n",
    "        self.search_algo = viterbi_search if use_viterbi else beam_search\n",
    "\n",
    "        # set evaluation/inference mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # map integers to characters in the alphabet\n",
    "        self.int2char = {i:c for i,c in enumerate(self.alphabet.replace(\"N\",\"\"), start=1)}\n",
    "\n",
    "    def __call__(self, return_basecalled_signals: bool=True):\n",
    "        print(\"Que me dice\")\n",
    "        # inference\n",
    "        accuracies, basecalled_signals = self.accuracy_all_dataset()\n",
    "\n",
    "        accuracy = np.array(accuracies).mean()\n",
    "\n",
    "        if self.path_fasta:\n",
    "            # create parent directory if it does not exists\n",
    "            Path(self.path_fasta).parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            # save basecalled signals to a fasta file\n",
    "            \n",
    "        \n",
    "        if return_basecalled_signals:\n",
    "            return accuracy, basecalled_signals\n",
    "        \n",
    "        return accuracy\n",
    "    \n",
    "    def basecall_one_batch(self, X):\n",
    "        \"Return basecalled signals in the chosen alphabet\"\n",
    "\n",
    "        preds  = self.model(X) # preds shape: (len-signal, item, size-alphabet)\n",
    "        basecalled_signals = list(\n",
    "            self.signal_to_read(signal=preds[:,item,:].detach().numpy(), use_viterbi=self.use_viterbi, rna=self.rna) \n",
    "            for item in range(preds.shape[1])\n",
    "            )\n",
    "\n",
    "        return basecalled_signals\n",
    "\n",
    "    def label_to_alphabet(self, label):\n",
    "        \"Map vector of integers to sequence in DNA or RNA alphabet\"\n",
    "        \n",
    "        return \"\".join([self.int2char[i] for i in label if i > 0])\n",
    "    \n",
    "    def accuracy_one_batch(self, batch):\n",
    "\n",
    "        X, y, output_len, target_len = (x.to(self.device) for x in batch)\n",
    "\n",
    "        basecalled_signals = self.basecall_one_batch(X)\n",
    "        ground_truth = np.apply_along_axis(lambda l: self.label_to_alphabet(l), 1, y.detach().numpy()) \n",
    "        accuracy_batch = [self.accuracy(ref=gt, seq=bs) for gt,bs in zip(basecalled_signals, ground_truth)]\n",
    "        \n",
    "        return accuracy_batch, basecalled_signals\n",
    "    \n",
    "    def accuracy_all_dataset(self,):\n",
    "        \"Returns a list with accuracies and another list with basecalled signals\"\n",
    "        basecalled_signals = []\n",
    "        accuracies = []\n",
    "        n_batches=len(self.test_loader)\n",
    "    \n",
    "        with tqdm(total=n_batches, leave=True, ncols=100, bar_format='{l_bar}{bar}| [{elapsed}{postfix}]') as progress_bar:\n",
    "\n",
    "            for n_batch, batch in enumerate(self.test_loader):\n",
    "\n",
    "                progress_bar.set_description(f\"Evaluating | Batch: {n_batch+1}/{n_batches}\")\n",
    "                accuracy_batch, basecalled_signals_batch = self.accuracy_one_batch(batch)\n",
    "                \n",
    "                accuracies.extend(accuracy_batch)\n",
    "                basecalled_signals.extend(basecalled_signals_batch)\n",
    "                \n",
    "                # progress_bar.set_postfix(train_loss='%.4f' % current_avg_loss)\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        return accuracies, basecalled_signals\n",
    "\n",
    "    def signal_to_read(self, signal, use_viterbi: bool = True, rna: bool = True):\n",
    "        \"Apply viterbi or beam search to a signal\"\n",
    "        \n",
    "        if use_viterbi is True:\n",
    "            seq, path = viterbi_search(signal, self.alphabet) \n",
    "        else:\n",
    "            seq, path = beam_search(signal, self.alphabet, beam_size=5, beam_cut_threshold=0.1)\n",
    "\n",
    "        return seq\n",
    "\n",
    "    def accuracy(self, ref, seq, balanced=False, min_coverage=0.0):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L354\n",
    "        \"\"\"\n",
    "        Calculate the accuracy between `ref` and `seq`\n",
    "        \"\"\"\n",
    "        # alignment = parasail.sw_trace_striped_32(seq, ref, 8, 4, parasail.dnafull) # this crashed, no meaningful error message\n",
    "        alignment = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        q_coverage = len(alignment.traceback.query) / len(seq)\n",
    "        r_coverage = len(alignment.traceback.ref) / len(ref)\n",
    "\n",
    "        if r_coverage < min_coverage:\n",
    "            return 0.0\n",
    "\n",
    "        _, cigar = self.parasail_to_sam(alignment, seq)\n",
    "\n",
    "        for count, op  in re.findall(self.split_cigar, cigar):\n",
    "            counts[op] += int(count)\n",
    "\n",
    "        if balanced:\n",
    "            accuracy = (counts['='] - counts['I']) / (counts['='] + counts['X'] + counts['D'])\n",
    "        else:\n",
    "            accuracy = counts['='] / (counts['='] + counts['I'] + counts['X'] + counts['D'])\n",
    "        return accuracy * 100\n",
    "\n",
    "\n",
    "    def parasail_to_sam(self, result, seq):\n",
    "        # From https://github.com/nanoporetech/bonito/blob/655feea4bca17feb77957c7f8be5077502292bcf/bonito/util.py#L321\n",
    "        \"\"\"\n",
    "        Extract reference start and sam compatible cigar string.\n",
    "\n",
    "        :param result: parasail alignment result.\n",
    "        :param seq: query sequence.\n",
    "\n",
    "        :returns: reference start coordinate, cigar string.\n",
    "        \"\"\"\n",
    "        cigstr = result.cigar.decode.decode()\n",
    "        first = re.search(self.split_cigar, cigstr)\n",
    "\n",
    "        first_count, first_op = first.groups()\n",
    "        prefix = first.group()\n",
    "        rstart = result.cigar.beg_ref\n",
    "        cliplen = result.cigar.beg_query\n",
    "\n",
    "        clip = '' if cliplen == 0 else '{}S'.format(cliplen)\n",
    "        if first_op == 'I':\n",
    "            pre = '{}S'.format(int(first_count) + cliplen)\n",
    "        elif first_op == 'D':\n",
    "            pre = clip\n",
    "            rstart = int(first_count)\n",
    "        else:\n",
    "            pre = '{}{}'.format(clip, prefix)\n",
    "\n",
    "        mid = cigstr[len(prefix):]\n",
    "        end_clip = len(seq) - result.end_query - 1\n",
    "        suf = '{}S'.format(end_clip) if end_clip > 0 else ''\n",
    "        new_cigstr = ''.join((pre, mid, suf))\n",
    "        return rstart, new_cigstr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n"
     ]
    }
   ],
   "source": [
    "Args=namedtuple(\"Args\", [\"path_test\", \"batch_size\", \"model\", \"path_checkpoint\", \"device\"])\n",
    "args = Args(\n",
    "\"../data/subsample_val.hdf5\",\n",
    "16,\n",
    "\"SimpleNet\",\n",
    "\"../output/training/checkpoints/SimpleNet-epoch1.pt\",\n",
    "None,\n",
    ")\n",
    "    \n",
    "PATH_TEST=args.path_test\n",
    "BATCH_SIZE=args.batch_size\n",
    "MODEL=args.model\n",
    "DEVICE=args.device\n",
    "PATH_CHECKPOINT=args.path_checkpoint\n",
    "\n",
    "if DEVICE is None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else: \n",
    "    device = DEVICE\n",
    "print(\"Device\" , device)\n",
    "\n",
    "model=eval(f\"{MODEL}()\")\n",
    "model.to(device)\n",
    "if device.type == \"cpu\":\n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT, map_location=torch.device('cpu')))\n",
    "else: \n",
    "    model.load_state_dict(torch.load(PATH_CHECKPOINT))\n",
    "model_output_len = model.output_len\n",
    "\n",
    "# dataset\n",
    "dataset_test = DatasetONT(recfile=PATH_TEST, output_network_len=model_output_len)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_test.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester=BasecallerTester(\n",
    "    model=model, \n",
    "    device=device,\n",
    "    test_loader=dataloader_test,\n",
    "    path_fasta=\"output/testing/basecalled_reads.fa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating | Batch: 13/13: 100%|███████████████████████████████████████████████████████████| [00:02]\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "accuracies, basecalled_signals = tester.accuracy_all_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0,\n",
       " 81.81818181818183,\n",
       " 85.71428571428571,\n",
       " 77.77777777777779,\n",
       " 100.0,\n",
       " 73.33333333333333,\n",
       " 85.71428571428571,\n",
       " 64.70588235294117,\n",
       " 72.72727272727273,\n",
       " 65.0,\n",
       " 87.5,\n",
       " 100.0,\n",
       " 85.71428571428571,\n",
       " 73.91304347826086,\n",
       " 72.72727272727273,\n",
       " 66.66666666666666,\n",
       " 78.57142857142857,\n",
       " 64.70588235294117,\n",
       " 63.63636363636363,\n",
       " 66.66666666666666,\n",
       " 100.0,\n",
       " 66.66666666666666,\n",
       " 75.0,\n",
       " 85.71428571428571,\n",
       " 70.96774193548387,\n",
       " 66.66666666666666,\n",
       " 80.0,\n",
       " 77.77777777777779,\n",
       " 77.77777777777779,\n",
       " 70.0,\n",
       " 100.0,\n",
       " 68.75,\n",
       " 75.0,\n",
       " 62.06896551724138,\n",
       " 87.5,\n",
       " 68.96551724137932,\n",
       " 61.29032258064516,\n",
       " 68.75,\n",
       " 78.57142857142857,\n",
       " 100.0,\n",
       " 62.5,\n",
       " 78.57142857142857,\n",
       " 60.86956521739131,\n",
       " 75.0,\n",
       " 76.47058823529412,\n",
       " 68.0,\n",
       " 70.83333333333334,\n",
       " 87.5,\n",
       " 72.72727272727273,\n",
       " 88.88888888888889,\n",
       " 83.33333333333334,\n",
       " 65.21739130434783,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 71.42857142857143,\n",
       " 90.9090909090909,\n",
       " 86.66666666666667,\n",
       " 77.77777777777779,\n",
       " 77.77777777777779,\n",
       " 70.0,\n",
       " 87.5,\n",
       " 81.81818181818183,\n",
       " 66.66666666666666,\n",
       " 66.66666666666666,\n",
       " 80.0,\n",
       " 58.97435897435898,\n",
       " 61.111111111111114,\n",
       " 100.0,\n",
       " 62.5,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 78.94736842105263,\n",
       " 73.33333333333333,\n",
       " 100.0,\n",
       " 77.77777777777779,\n",
       " 100.0,\n",
       " 81.81818181818183,\n",
       " 68.75,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 64.70588235294117,\n",
       " 70.0,\n",
       " 72.22222222222221,\n",
       " 70.58823529411765,\n",
       " 77.77777777777779,\n",
       " 70.96774193548387,\n",
       " 66.66666666666666,\n",
       " 82.6086956521739,\n",
       " 61.29032258064516,\n",
       " 71.42857142857143,\n",
       " 64.51612903225806,\n",
       " 68.75,\n",
       " 70.73170731707317,\n",
       " 59.183673469387756,\n",
       " 75.0,\n",
       " 83.33333333333334,\n",
       " 88.88888888888889,\n",
       " 100.0,\n",
       " 78.57142857142857,\n",
       " 64.28571428571429,\n",
       " 80.0,\n",
       " 80.0,\n",
       " 78.57142857142857,\n",
       " 76.47058823529412,\n",
       " 69.56521739130434,\n",
       " 62.5,\n",
       " 80.0,\n",
       " 71.42857142857143,\n",
       " 75.0,\n",
       " 100.0,\n",
       " 69.23076923076923,\n",
       " 77.77777777777779,\n",
       " 72.72727272727273,\n",
       " 76.47058823529412,\n",
       " 88.88888888888889,\n",
       " 83.33333333333334,\n",
       " 62.5,\n",
       " 100.0,\n",
       " 70.37037037037037,\n",
       " 91.66666666666666,\n",
       " 57.692307692307686,\n",
       " 87.5,\n",
       " 69.23076923076923,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 76.47058823529412,\n",
       " 72.72727272727273,\n",
       " 65.51724137931035,\n",
       " 68.18181818181817,\n",
       " 68.96551724137932,\n",
       " 73.33333333333333,\n",
       " 81.81818181818183,\n",
       " 70.83333333333334,\n",
       " 76.19047619047619,\n",
       " 73.07692307692307,\n",
       " 85.71428571428571,\n",
       " 65.51724137931035,\n",
       " 71.42857142857143,\n",
       " 72.72727272727273,\n",
       " 100.0,\n",
       " 63.1578947368421,\n",
       " 57.14285714285714,\n",
       " 100.0,\n",
       " 77.77777777777779,\n",
       " 64.28571428571429,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 85.71428571428571,\n",
       " 85.71428571428571,\n",
       " 63.33333333333333,\n",
       " 73.68421052631578,\n",
       " 64.28571428571429,\n",
       " 80.0,\n",
       " 70.37037037037037,\n",
       " 57.692307692307686,\n",
       " 77.77777777777779,\n",
       " 70.37037037037037,\n",
       " 68.42105263157895,\n",
       " 83.33333333333334,\n",
       " 75.0,\n",
       " 62.5,\n",
       " 91.66666666666666,\n",
       " 77.77777777777779,\n",
       " 76.19047619047619,\n",
       " 66.66666666666666,\n",
       " 75.0,\n",
       " 80.0,\n",
       " 100.0,\n",
       " 71.42857142857143,\n",
       " 81.81818181818183,\n",
       " 92.3076923076923,\n",
       " 100.0,\n",
       " 64.0,\n",
       " 73.91304347826086,\n",
       " 100.0,\n",
       " 71.42857142857143,\n",
       " 83.33333333333334,\n",
       " 75.0,\n",
       " 75.0,\n",
       " 100.0,\n",
       " 66.66666666666666,\n",
       " 66.66666666666666,\n",
       " 76.47058823529412,\n",
       " 66.66666666666666,\n",
       " 77.77777777777779,\n",
       " 71.42857142857143,\n",
       " 100.0,\n",
       " 80.0,\n",
       " 100.0,\n",
       " 75.0,\n",
       " 76.19047619047619,\n",
       " 64.28571428571429,\n",
       " 60.60606060606061,\n",
       " 81.81818181818183,\n",
       " 60.71428571428571,\n",
       " 90.0,\n",
       " 68.18181818181817,\n",
       " 66.66666666666666,\n",
       " 75.86206896551724,\n",
       " 66.66666666666666]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AGAGAGAGAAGAGAAGAGAGAGAAG',\n",
       " 'GAAGAAAGAAGAGAAAAAAAAAGAAAG',\n",
       " 'AGAAGAGAGAGAGAAGAGAGAGAGAGAGAGAGAGA',\n",
       " 'GAAAGAGAGAAGAGAAAAAAAGAAAG',\n",
       " 'GAGGGAGAAGAGAGGAGAGAGAGAGAGAGAG',\n",
       " 'AGGAGGAGAGGGAAAGAGACGAGAGAGAGAGAGAGAGAAGAGAGGAGAAAAAGAG',\n",
       " 'AGAGAAAGAGAGAAGAGAAAGAAAGAGAGAAGAGAGAGAGAGA',\n",
       " 'AGAGACGAGAGAGGGAGAGAGGAAGGAGAGAGAG',\n",
       " 'AGAGAGAAGAAAGGAAGAGAGAGAAAAG',\n",
       " 'GAGAGAGGAGAGAGAGAAGAGAGAAGAAAA',\n",
       " 'GAGAAGAGAAAGAAGAGAGAGAAGAGA',\n",
       " 'GAGAGAGAGAGGAGAAGAGAAGAAGAGAGAGAAGAAG',\n",
       " 'GAAAAAAAAAGAGAGAGAGAAAGAGAAGACGAGAGAGGG',\n",
       " 'AGAAAGAGAGAGAGAGAAGAGAGAAGAGA',\n",
       " 'GAGAGAAAGAGAGAGAGAAAGAGAAGAGAAGAGAAGAGAGAGAAG',\n",
       " 'GAAGAGAGAGAAAAGAGAGAGAGAGAAGAGAAGAGAGAGAGAGAAGAGAA',\n",
       " 'AGAGAGAAGGAGGGAGAAAGAGAGAGAGAGAAAAAAAGAAGAAG',\n",
       " 'GAGAGAGAGAAAAAGAAGAGAGACGAGAGGAGGGAGAGAG',\n",
       " 'GAGAGAAAGAGAGAGAAAGAAGAGAAAAAG',\n",
       " 'AGAAAGAACGAGAAGAAAAA',\n",
       " 'AAGAGAGAAGAAGAGAGAGAG',\n",
       " 'AGAGAGAGAAAGAAGAGGAAAGAGAAAGAGGAGAGAAGAGAGA',\n",
       " 'GAAGAGAGAGAGAGAGAAAGAGAGAGAGAAAGAGAA',\n",
       " 'GAGAGAAGAGAAGAGAGAGACAGAAAGACGAGAAGAGAGAG',\n",
       " 'AGAAAGGAGAGAAAGAGAGAAGAGAGAGAAGAGAAGAAGAG',\n",
       " 'AGGAGAGAAAGAGGAAAG',\n",
       " 'GAGAAGAGAAAGAAAGAGAGAG',\n",
       " 'AAAGAGAGAGAGAGAGGAGAGAGAAGAAGAAGAGAG',\n",
       " 'GAGAAGAGGGAGAAGAGAGAGAGAAAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAGAGAAGAGAGAGAGAGAAGAGAGAAGAAAGAGAGGG',\n",
       " 'AGAGAAAGAGAGAAGAGAAGAGAGAGAGAGAGAGAGAGGAAA',\n",
       " 'AAAAAAAAGAGAAGAGAAGAGAGAGAGAGAGAGAGAAGAG',\n",
       " 'GAGGAAGAGAGAGAAGAGAGAGAAGAGAGAGAAGAGAGA',\n",
       " 'GAGAAGAGAGAAGAGAGAGAGAGAGACGAAGAGAGAGGAGA',\n",
       " 'AGAAGAAAGAAAAAAAAAGAGAGAGAGAGAAGA',\n",
       " 'AGAGAGAGAAAGAGAGAGGAAGAGAGA',\n",
       " 'AAAAAGAAAGAAGAGAGAGAGAGAGAGAGAGAGAGAAGAGAG',\n",
       " 'AGAGAGAGAGAAAGGAGAAAAGAG',\n",
       " 'GAGAGAAAAGAGAGAGGAGAAGAGAGA',\n",
       " 'AAGAGAGAGAAGAGAGAGAAAGAGAAGAGAGAGAGAGAGAGGAGAGAGAGAG',\n",
       " 'GAAAGAGAAAGAGAGAGAAGAGGAAAGGAGAG',\n",
       " 'GAGAGAGGGAGAGAAGAGAGAGAGAGA',\n",
       " 'AGAGAGAGAAGAGAGAGAAGAGAAGAAAAGAAGAAA',\n",
       " 'GAGAGAAGAAGAGAGAAAAGAGAAGAGGAGAGAGAGAGAGA',\n",
       " 'AGAGAAGAGAAGAGGAGAAGAGAAGAGAGAGAGGAGAGA',\n",
       " 'GAAAGAGAGAGAGAAGAGAGAAGAAGAAGAGAG',\n",
       " 'GAGAGAAGAGAGAGAGAAGGAGAGAG',\n",
       " 'AGAGAAGAGAGAAAGAGAGGAGAGAGAGAGAGA',\n",
       " 'GAGAAGAAAGGAGAAGAAGAGAGAGAAAAAGA',\n",
       " 'AGAGAGAAAAAGAGAAAGAGAGAGAAGAGAAGGAAAAAAAGA',\n",
       " 'GAAAAGAGAAAGAGGAGAAAAAGAGAGAAGAAGGA',\n",
       " 'AGAGAGAGAGGAGGAGAGAGAAAGAGACAGAGAGGAGAGGAA',\n",
       " 'GAGAGAGAAGAGAGAGAGAGAGAGAGAGAGAGA',\n",
       " 'AAAGAGAGAGACAGAGAAGAGAGAGAAAGAGAGAGAAGA',\n",
       " 'GGAGAGAAAAAGAAGAGAGAGAAGAGAGAAGAGA',\n",
       " 'GAGGAAAGAGGAAGAGAAAAAGAGAGA',\n",
       " 'GAGGGAGAGAGAGAGAGAGAGAAAAAGAAGAGAAGAGA',\n",
       " 'AGAGGAAAGAAGAGAAGAGAGAGAGAG',\n",
       " 'GAGAAGAGAAAGAGAGAAAGAGAGAGAGAGAGGAGA',\n",
       " 'GAGAGAGAGAGAGAGGACAGAGAGAAGAGAGAGAG',\n",
       " 'GAGGAAAGGAGAGAGAAGAGAGAAG',\n",
       " 'GAAGAAAAGAGAGAGAGGAGAGAAGAGAAGAGA',\n",
       " 'AGGAGAGAAGAAAGAGAGAGAGAGAGAA',\n",
       " 'AGAAAAGAGAGAGAAGAAGAGAAG',\n",
       " 'AGAGAGAGAAAGAAGAAAAAAGAAGAACG',\n",
       " 'GAGACGAGAAAAGAGAAGGGAGAGAGAGAGGAG',\n",
       " 'AGAGAGAGAGAGAGAAGGAAAGAGAAGAAGAAAAGAGAAGAGAA',\n",
       " 'GAGGAAGAGAAGAGGAGGAGAAAGAAGAGAG',\n",
       " 'GAGAAAGAGAAGGAGAGAGAGAGAGAAGAGAGAA',\n",
       " 'GAGAAAAGAGAGAGAGAGAAAGAGAGAGAAAGAGGAG',\n",
       " 'GAGAGGAGAGAAGAGAGAGAGAGAAAGAAAGAAAGAGAAGAGAG',\n",
       " 'AGAGAGAGAAGGAGAGAAGAGAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAAGAGAGAGAAGAGAGAGAAGAGAGAGAGAAGAAAAAGAGA',\n",
       " 'AGAGAAGAAGGAGAGAGAAAAGAGAGAGAGA',\n",
       " 'AGAGAGAGAGAGAGAGAGAGAGAGAA',\n",
       " 'AGGGAAGAGAGAGAGAGAAAAGAGAGAAGAAGAGA',\n",
       " 'GAGAAAAAAGAGAGAGAG',\n",
       " 'GAAAGGAGAGAGGAGAGAGAGGGGAGAGAGACG',\n",
       " 'AGGAGAGAGAGAGAGAGAGA',\n",
       " 'GAAGAGAGAGAAGAGAGAGAGAAGAAGAGAGAGGAGAAAG',\n",
       " 'AGAGAAAAGAGAGAGAGAAAAGAAAGAGAGGGAGAGAGAGA',\n",
       " 'AAGAGAGAAAGAAGAAGAGAAAAGAAAAGAGAGAGA',\n",
       " 'GAGAAAGAGAGAGAGAGAGAGAAGGAAGAGAGAA',\n",
       " 'GAGAAGAGAGAAGAGAAA',\n",
       " 'GAGAAAAGAGAGAAGAGGAGAGAGAAAAAGAAGAGAGAGA',\n",
       " 'AAAGAAGAGAGAGAAGAGAGAGAGAGGAAA',\n",
       " 'GAGAGAAAGAGAGAGAGAGAGGAGAGAAGAGAAGAG',\n",
       " 'AGAAGAGAGGAGAGAGAGAG',\n",
       " 'GAGGAGAGAGAGAGGAAAGAAAGAGAGAGAAGA',\n",
       " 'AGAGAGAAGAGAAGAGAAGAGAAAAGAGAGAAAGAGAGAA',\n",
       " 'AAGAGAAAAGAGAGAGAGAGAAGGAAGACGAAAAGAGAAAG',\n",
       " 'AAGGAGAGAGGAGAGAAAAGAAAGAAGAGAG',\n",
       " 'AGAGAGAAAGAGGAGAAGAGAGAGAAGAGGAGAGAGAGAGAGAG',\n",
       " 'AGACACAAAAAGAGAGAGAGAGGAGGGAGAGAGGGGGGAG',\n",
       " 'GAGAGAGGAAGAAGGAAAGAGAGAAGAGAAAAG',\n",
       " 'AGAGAGAAGAAAAAAGAGAGAGAG',\n",
       " 'GAGAAAAGAAAGGAAAGAGAGAGAGAGAGGAGAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAGAAA',\n",
       " 'AGAGAGAGAGAGAAGAGAGAGAAGAGAGAAGA',\n",
       " 'ACGAGAGAGAGAGAAGAGAAGAGAGAGAGAGAGAGAAGAAG',\n",
       " 'GAGAGAAAAAGAGAAAAGAAGAGGGAGAGAAGA',\n",
       " 'GAAGAGAAAGAAGACGAGAGAGAAGAGAAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAGAGAGAAGAAAAGAAGAAG',\n",
       " 'AGGAGGAGAGAAAGAGAGAGAGAGGAGAAGAGGAG',\n",
       " 'AGAGAGAGAGAGAGGAGAGAAGAAAGAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAAGAAAGAA',\n",
       " 'AGAAGAGAAGAAGAGAGAAAAGAGAGAGAG',\n",
       " 'AGAGAAGAGAGAGAGAGAAGAAAGAGGAGAGAGAGAGAGAGAGA',\n",
       " 'AAAGAAGAGAGAAAAGGAGAGAGAGAGAGAGA',\n",
       " 'GAGAAAAGAGAAGAAGAGAGAGAGAGAGAGAGAGAGAGAG',\n",
       " 'GAGGGAGAAAGAAGAGAGAAGAGGGGGAGAGAGA',\n",
       " 'AAGAGGAGAGAGAGAGAGAGAAGAGAGAAGAGAAGAAGAAGAGAGA',\n",
       " 'GAGAGAGAGAAAGAGAGAAGGAGAAGAAGAAGAGAGAGAGAGA',\n",
       " 'AGAAGAAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'AGAAGAGAAGAGAGAGAAAAAAAGAGAGAGAGA',\n",
       " 'GAGAAAGAGAGAAAGAGAAG',\n",
       " 'GGAGAAGAAGAGAAGAAGAGAGAG',\n",
       " 'AGAGGAAAGAAGAGAAAGAAAGAGAG',\n",
       " 'AGAAGAAGAGAAGAGAGACGAGGAAGAAGAGAGAG',\n",
       " 'GAAAGAGAGAGGAGAGAGAGGAGAAAGAAGAGAGAAG',\n",
       " 'AGAGAAAGAGAAAGAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAAAGGAGAGAGAGACGAAAAG',\n",
       " 'AAAAGAGAAGAAGAGACAGAAGAG',\n",
       " 'GAGAGAGAAAGAGAAGGAGAGAGAAAGAGAGAGAGAGG',\n",
       " 'GAGAGAGGAGAGAAGAAGGAGAGAGAGAAAGAAGAGAGAGAAACG',\n",
       " 'GAGGAGAGAGAGAGAGACACG',\n",
       " 'GAGAGAGAAAGAGAGGGAAGAGAAAAGGGAAAGAAGAGAAGAG',\n",
       " 'AGAGCGGAAGACGACGAGAAAGAGAGA',\n",
       " 'GAAGAGAAGAGAGAGAGAGAGAAGAGAGAGAGAGA',\n",
       " 'GAAGAGGAGAGAGAGAGGGAGGAAGAGAGAACAGAGAG',\n",
       " 'GGAGAGAGAAAGAGAGAGAGAGAGAGAAAAGAGAGAAGA',\n",
       " 'GAAAGGGAGAAAGAAGAGAGAGAGAGA',\n",
       " 'GAAAGAGAGAGAAAGAGAGAGGAGAGAGAGAGAAG',\n",
       " 'AGAAAGAGAGAGAGAGAGAGAGAGACGAAGAGAAGAG',\n",
       " 'AAGAAGAAGAAAGAAAAGAAAGAAAAGGAGAGAGAAAGAAGAAG',\n",
       " 'GAGAGAAGAGAAGAAAGAGAAGAGAGAGAA',\n",
       " 'AGAGAGAGAGAACGAGAAGAGAAGAGAAGAGGAAG',\n",
       " 'AAGAGAGGGAGAGAAAGAGAAAGAGAG',\n",
       " 'GAGAAAAGAAGAGAAGAAAGGGAAAGA',\n",
       " 'GAGAGAGGAGAAAAAAGAGAGAGAGAGAGAAGAGAGA',\n",
       " 'AAGAGAGAGAAGAGAGAGAGAAGAGAGACGAGAAGAGAGAG',\n",
       " 'AGAGAGAGAGAAGAGAGAGAGGAGAGAGAGAG',\n",
       " 'AAAGAAGAGAAGGAAAGAA',\n",
       " 'AGAAGAGAGAAGAGAAGGAGAGAAAAAA',\n",
       " 'AGAGAAGAGAAGAGAGAGAGAAAGAGAGAGAG',\n",
       " 'GAGAGAGAGAAGAGAAAGAAAAAGAGAGGAGAGAA',\n",
       " 'AGAAAAGAAGAGAGAGAAGAGAAAA',\n",
       " 'AGAGAGAGAAGAGAGAGAGGAGAAGAGAAAGG',\n",
       " 'AGAGAAGAAAAAGAGAGAAAAAGAAGAGAAA',\n",
       " 'GAGAGAGGAAAGAGAGAGAAGAGGAGAGAAGAAGA',\n",
       " 'GAGAGAGAGAGAAGAAGAGAAAGAAAGAGAGAG',\n",
       " 'AGAGAGAGAGAGAGAGAGAGAAAGAGAGAG',\n",
       " 'GAGAAGAGAGAAAAAAGAGAGAGAAAAG',\n",
       " 'GAAGAGAGAGAGAAGAGAGAAGAGAAGAG',\n",
       " 'GAACGGGAAGAAGAGAGAGGAGAGAAAAGA',\n",
       " 'AAGAGAAGAAGAGAGAGAGAGAGAGAGAGAGGAGAG',\n",
       " 'GAAGAAGAGAGAGGGGAGAAGAGAAGAAGAAGAG',\n",
       " 'AGAAAGAGAGAAAGAGGAGA',\n",
       " 'GAAAGAAAGAAGAGAAAGAGAGGAGAGAGAAAG',\n",
       " 'AGAAAAGAGAGAGAGAGGAAGAAGAGAGAGAGAAG',\n",
       " 'GAGAGAGAAGAGAAAGAGAGAGAGAGA',\n",
       " 'AAAAGAGAAGAGAGAGAGAGAGAGAGAAGAGAGAGG',\n",
       " 'GAGAAGAGGAGAGAGAAGAGAGAGGAAGAAGAGAGAGAG',\n",
       " 'AGAGAAGAAGAGAGAGAGAGAGAAGAGAGAGAGAGAG',\n",
       " 'GAGAGAGAGGAGGAGAGAGAGAGAGAGAGAGA',\n",
       " 'AGAAAAGAGAGAAAAGAGAGAGAAGAGAGAGAGAGAGAGA',\n",
       " 'AGAAGAAGAGAGAGAGAAGAGAGAGAGAAG',\n",
       " 'GAGAGAAGAGAAAAAGAGAGAGAGAAAA',\n",
       " 'GAGAGAGAGAGAGAAAGAGGAGAAAGAAGAGAAG',\n",
       " 'GAGAAGAGAGAGAAGAGAGAGAGAGAGAGAGAAGAGAGAAAG',\n",
       " 'AGAGGAGAGAGA',\n",
       " 'GAGAGAGAAAAGAAAGAA',\n",
       " 'AGAGAAAAAGAAAGAGAGAGAGAGAAAGAGAAGAA',\n",
       " 'AGAGAGAAAGAGAGAGAGAAGGAAGAGAGGA',\n",
       " 'GAGGAGAAGAGAAAGGAGAGAAGAGAGAGAGAGAGA',\n",
       " 'AAAAGAGAGGAGAGAGAGAGAGA',\n",
       " 'AGAGAAAAGAAAAGAAAAAAAAAAAA',\n",
       " 'GAGAGAGAGAGAAGAGAGAGAGAGAAGAGAG',\n",
       " 'AGAAGGGAAGAAGAGAGAAGAGAGAAGGAGAGAAGAGA',\n",
       " 'GAAGAAGAAGAGAGAAGAGAGAGAGGAGAGAGAGAGAGAGAGAAA',\n",
       " 'AGAGAGAAGAGAGAAAAGGAGAAAAGAGAGAGAAGGAGAGAGAGAGAGG',\n",
       " 'GAGAAAAGGAGAAGAAAGAAGAAGAGGAGAGAGAGAA',\n",
       " 'AGAGAGAAAAGAGAAGAGAGAAGAGAGAGAGAAG',\n",
       " 'AGAAAGAGAGAAGAGAAGAAG',\n",
       " 'GAGAGAGAGAGAAGAGAGAAAGAGAGAGAGAGAAGAA',\n",
       " 'GAGAGAAGAGAGAGAAGAAGAGAGAGGAAG',\n",
       " 'GAGAGAGAGAGAGAGAGAGAGAGAGAAGAAGAGAGAGAGAGGAGAAAAAAGA',\n",
       " 'GAAGAGAGAAGAGAGAGAGAAGAGAAAAGAGAGAG',\n",
       " 'GAAGGAGAAAAAGAGAAGAGAAAGAGGAG',\n",
       " 'AGAGAGAAGGAGAGAGAGAGA',\n",
       " 'GAGAAAGAGAAGAGAGAGAGAGGAGAGAAG',\n",
       " 'AGAGAGGAGAAGAAAAAGAGAGGAAGAGAGAGAGAGAGAAGAAG',\n",
       " 'GAGGAGGAAGAGAGAGAGAGAGAGAAGAGAGAGAGGAGAGAGAG',\n",
       " 'AAGAGAGAGAAGAGAAGAGAGAGAGAAGAGAAAA',\n",
       " 'GAGAGAGAAAAGAGAGAGACGAAGAGAGAAGAGA',\n",
       " 'GGAGAAAGAAGAGAGAGAGAAGAGAAGAGAGAAAGGAGAGA',\n",
       " 'GAGAGAGAGGAGAGAGAGAGAGAGAAAAAAGGAGAAGAGA',\n",
       " 'AAGAGAAAGAGGAGAGAGAAGGAGGAGG',\n",
       " 'GAGAGAAGAGAGAGAGAAGAGAGAGAAGAGAG',\n",
       " 'AGAAGAAGAAGAGAGAGAGA']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basecalled_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_fasta = \"../output/test/basecalled_signals.fa\"\n",
    "Path(path_fasta).parent.mkdir(exist_ok=True, parents=True)\n",
    "with open(path_fasta, \"a\") as fp:\n",
    "    for j,read in enumerate(basecalled_signals):\n",
    "        fp.write(f\">signal_{j}\\n\")\n",
    "        fp.write(read + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, ref = (\"ACGTACGTACGTACGAGCAT\",\"ACGACTACGACTACACACAC\")\n",
    "result = parasail.sw_trace(seq, ref, 8, 4, parasail.dnafull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rstart, new_cigstr = tester.parasail_to_sam(result, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '4S3=1I2=1I5=4S')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstart, new_cigstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_test))\n",
    "model.eval()\n",
    "X, y, output_len, target_len = (x.to(device) for x in batch)\n",
    "preds = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 4096]), torch.Size([501, 16, 5]), torch.Size([16, 271]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, preds.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 16, 5)\n"
     ]
    }
   ],
   "source": [
    "batch_signals = preds.detach().numpy()\n",
    "print(batch_signals.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
